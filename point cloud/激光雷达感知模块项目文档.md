   

# 激光雷达感知模块项目文档

商用车开发院 智能网联车开发部 吴再霖

Update：2023-05-30

**Lidar Project Work**

[TOC]



## 1.文件路径解析

激光雷法感知模块相关程序及文件存储于 L4_2022_perception-mastor/modules/perception

下文中以上路径由符号”~“指代：

~/common：公共目录

~/lib：一些基础库,包括对线程、时间管理等

~/inference：深度学习推理模块，存有Caffe等推理框架

~/carema:  摄像头视觉感知模块

~/data:  相机的内参和外参

~/fusion:  融合相关

~/lidar:  激光雷达相关

​    |----app:  lidar应用类，主处理类，最终算法为实例化该文件夹下的类来实现 

​    |----common：定义lidar感知模块通用数据结构，例如LidarFrame，通用方法等

​    |----lib：激光雷达感知算法实现库

~/map:  地图

~/onboard:  子模块入口

​    |--component：感知模块组件，实现对象

​    |--proto：配置文件数据格式，利用Protobuf

~/production:  感知模块入口

​    |--launch：启动文件

​    |--dag：关系拓扑文件

​    |--conf：配置文件

​    |--data：感知算法参数/模型文件

~/radar:  毫米波雷达相关

~/tool:  相关工具

​    |--simulation_tools：消息转换工具（可视化）

​    |--visualization:  基于ROS（RViz）可视化工具

~/launcher_perception:  感知启动部分（自定义）

​    |--launch：启动文件

​    |--dag：关系拓扑文件

​    |--conf：配置文件

​    |--params：位置转换关系（外参）文件

​    |--data：感知算法参数/模型文件

## 2.CyberRT — 消息分发机制

Apollo Cyber RT 是一个开源、高性能的运行时框架，专为自动驾驶场景而设计。针对自动驾驶的高并发、低延迟、高吞吐量进行了大幅优化.

### 2.1 常用术语

**Component**:  在自动驾驶系统中，模块（如感知、定位、控制系统等）在 Cyber RT 下以 Component 的形式存在。不同 Component 之间通过 Channel 进行通信。Component 概念不仅解耦了模块，还为将模块拆分为多个子模块提供了灵活性。

**Channel**:  Channel 用于管理 Cyber RT 中的数据通信。用户可以发布/订阅同一个 Channel，实现 P2P 通信。

**Task**:  协程，Task 是 Cyber RT 中异步计算任务的抽象描述。

**Node**:  Node 是 Cyber RT 的基本组成部分。每个模块都包含一个 Node 并通过 Node 进行通信。通过在节点中定义 Reader/Writer 或 Service/Client，模块可以具有不同类型的通信形式。

**Reader/Writer**:  Reader/Writer 通常在 Node 内创建，作为 Cyber RT 中的主要消息传输接口。

**Service/Client**:  除 Reader/Writer 外，Cyber RT 还提供了用于模块通信的 Service/Client 模式。它支持节点之间的双向通信。当对服务发出请求时，客户端节点将收到响应。

**Parameter**:  参数服务在 Cyber RT 中提供了全局参数访问接口。它是基于 Service/Client 模式构建的。

**服务发现**:  作为一个去中心化的框架，Cyber RT 没有用于服务注册的主/中心节点。所有节点都被平等对待，可以通过“服务发现”找到其他服务节点。使用 `UDP` 用来服务发现。

**CRoutine**:  参考协程（Coroutine）的概念，Cyber RT 实现了 Coroutine 来优化线程使用和系统资源分配。

**Scheduler**:  为了更好地支持自动驾驶场景，Cyber RT 提供了多种资源调度算法供开发者选择。

**Message**:  Message 是 Cyber RT 中用于模块之间数据传输的数据单元。

**Dag文件**：Dag 文件是模块拓扑关系的配置文件。您可以在 dag 文件中定义使用的 Component 和上游/下游通道。

**Launch文件**：Launch 文件提供了一种启动模块的简单方法。通过在 launch 文件中定义一个或多个 dag 文件，可以同时启动多个模块。

**Record 文件**：Record 文件用于记录从 Cyber RT 中的 Channel 发送/接收的消息。回放 Record 文件可以帮助重现 Cyber RT 之前操作的行为。
**Record 文件**：Record 文件用于记录从 Cyber RT 中的 Channel 发送/接收的消息。回放 Record 文件可以帮助重现 Cyber RT 之前操作的行为。

### 2.2 Cyber数据处理流程

![image-20230605104444683](C:\Users\wuzailin\AppData\Roaming\Typora\typora-user-images\image-20230605104444683.png)

1.Node节点中Writer往通道里面写数据；

2.通道中Transmitter发布消息，通道中Receiver订阅消息；

3.Receiver接收到消息后，触发回调，触发DataDispather进行消息分发；

4.DataDispather接收到消息后，把消息放入CacheBuffer，并且触发Notifier，通知对应的DataVisitor处理消息；

5.DataVisitor把数据从CacheBuffer中读出，并且进行融合，通过notifier_唤醒对应的协程；

6.协程执行对应的注册回调函数，进行数据处理，处理完成后进入睡眠状态.

### 2.3  Cyber流程关系分析

**1.Component和Node的关系**

Component是cyber中封装好的数据处理流程，对用户来说，对应自动驾驶中的Planning Component, Perception Component等，目的是帮助用户更方便的订阅和处理消息，事实上**Component模块在加载之后会执行"Initialize()"函数**，这是个隐藏初始化过程，对用户不可见。在"Initialize"中，Component会创建一个Node节点，概念上对应ROS的节点，**每个Component模块只能有一个Node节点**，即每个Component模块有且只能有一个节点，在Node节点中进行消息订阅和发布。

**2.Node和Reader\Writer的关系**

在Node节点中可创建Reader订阅消息，也可以创建Writer发布消息，每个Node节点中可以创建多个Reader和Writer。

**3.Reader和Receiver,Writer和Transmitter,Channel的关系**

一个Channel对应一个Topic，概念上对应ROS的消息通道，每个Topic是唯一的。而Channel中包括一个发送器(Transmitter)和接收器(Receiver)，通过Receiver接收消息，通过Transmitter发送消息。

一个Reader只能订阅一个通道的消息，如果一个Node需要订阅多个通道的消息，需要创建多个Reader。同理一个Writer也只能发布一个通道的消息，如果需要发布多个消息，需要创建多个Writer。

Reader中调用Receiver订阅消息，而Writer通过Transmitter发布消息。

**4.Receiver, DataDispatcher和DataVisitor的关系**

每个Receiver接收到消息后，则会触发回调，回调中触发DataDispather（消息分发器）发布消息，DataDispather是一个单例，所有的数据分发都在数据分发器中进行，DataDispather将数据放到对应的缓存中，之后Notify(通知)对应的协程（事实上此处调用的是DataVisitor中注册的Notify）去处理消息。

DataVisitor（消息访问器）是一个辅助的类，**一个数据处理过程对应一个DataVisitor，通过在DataVisitor中注册Notify（唤醒对应的协程，协程执行绑定的回调函数），并且注册对应的Buffer到DataDispather**，这样在DataDispather的时候会通知对应的DataVisitor去唤醒对应的协程。

即DataDispather（消息分发器）发布对应的消息到DataVisitor，DataVisitor（消息访问器）唤醒对应的协程，协程中执行绑定的数据处理回调函数。

**5.DataVisitor和Croutine的关系**

实际上DataVisitor中的Notify是通过唤醒协程（为了方便理解亦可认为线程，可以理解为一个线程池，通过线程池绑定数据处理函数，数据到来之后就唤醒对应的线程去执行任务），每个协程绑定了一个数据处理函数和一个DataVisitor，数据到达之后，通过DataVisitor中的Notify唤醒对应的协程，执行数据处理回调，执行完成之后协程进入休眠状态。

**6.Scheduler, Task和Croutine**

通过上述分析，**数据处理的过程是通过协程完成的，每一个协程被称为一个Task，所有的Task(任务)都由Scheduler进行调度**。事实上Cyber的实时调度由协程去保障，并且可以灵活的通过协程去设置对应的调度策略，同时协程依赖于进程，本项目在linux中设置进程的优先级为实时轮转，先保障进程的优先级最高，然后内部再通过协程实现对应的调度策略。

### 2.4 Cyber 组件(Component)处理流程

##### 2.4.1 Component介绍

component是cyber中设计的实现对象，component加载时自动创建node，通过node订阅和发布对应的消息，每个component有且只能对应一个node；

component对用户提供2个接口"Init()"和"Proc()"，用户在Init中进行初始化，在"Proc"中接收Topic执行具体的算法。对用户隐藏的部分包括component的"Initialize()"初始化，以及"Process()"调用执行。

##### 2.4.2 Component工作流程

component的工作流程如下：

1. 通过继承"cyber::Component"，用户自定义一个模块，并且实现"Init()"和"Proc()"函数。编译生成".so"文件。
2. 通过classloader加载component模块到内存，创建component对象，调用"Initialize()"初始化。（Initialize中会调用Init）
3. 创建协程任务，并且注册"Process()"回调，当数据到来时，唤醒对象的协程任务执行"Process()"处理数据。（Process会调用Proc）

综上所述，component帮助用户把初始化和数据收发的流程进行了封装，减少了用户的工作量，component封装了整个数据的收发流程，component本身并不是单独的一个线程执行，模块的初始化都在主线程中执行，而具体的任务则是在协程池中执行。

##### 2.4.3 Cyber入口

cyber的入口在"cyber/mainboard/mainborad.cc"中，主函数中先进行cyber的初始化，再启动cyber模块，最后运行，一直等到系统结束。

```cpp
int main(int argc, char** argv) {
  // 1. 解析参数
  ModuleArgument module_args;
  module_args.ParseArgument(argc, argv);

  // 2. 初始化cyber
  apollo::cyber::Init(argv[0]);

  // 3. 启动cyber模块
  ModuleController controller(module_args);
  if (!controller.Init()) {
    controller.Clear();
    AERROR << "module start error.";
    return -1;
  }
  
  // 4. 等待直到程序退出
  apollo::cyber::WaitForShutdown();
  controller.Clear();
  return 0;
}
```

##### 2.4.4 Component动态加载

cyber主函数在"ModuleController::Init()"进行模块的加载，具体的加载过程在"ModuleController::LoadModule"中。

```cpp
bool ModuleController::LoadModule(const DagConfig& dag_config) {
  const std::string work_root = common::WorkRoot();

  for (auto module_config : dag_config.module_config()) {
    // 1. 加载动态库
    class_loader_manager_.LoadLibrary(load_path);
    
    // 2. 加载消息触发模块
    for (auto& component : module_config.components()) {
      const std::string& class_name = component.class_name();
      // 3. 创建对象
      std::shared_ptr<ComponentBase> base =
          class_loader_manager_.CreateClassObj<ComponentBase>(class_name);
      // 4. 调用对象的Initialize方法
      if (base == nullptr || !base->Initialize(component.config())) {
        return false;
      }
      component_list_.emplace_back(std::move(base));
    }
    
    // 5. 加载定时触发模块
    for (auto& component : module_config.timer_components()) {
      // 6. 创建对象
      const std::string& class_name = component.class_name();
      std::shared_ptr<ComponentBase> base =
          class_loader_manager_.CreateClassObj<ComponentBase>(class_name);
      // 7. 调用对象的Initialize方法
      if (base == nullptr || !base->Initialize(component.config())) {
        return false;
      }
      component_list_.emplace_back(std::move(base));
    }
  }
  return true;
}
```

模块首先通过classloader加载到内存，然后创建对象，并且调用模块的初始化方法。component中每个模块都设计为可以动态加载和卸载，可以实时在线的开启和关闭模块，实现的方式是通过classloader来进行动态的加载动态库。

##### 2.4.5 Component初始化

component一共有4个模板类，分别对应接收0-3个消息，我们这里主要分析2个消息的情况，其它的可以类推。

```cpp
template <typename M0, typename M1>
bool Component<M0, M1, NullType, NullType>::Initialize(
    const ComponentConfig& config) {
  // 1. 创建Node
  node_.reset(new Node(config.name()));
  LoadConfigFiles(config);

  // 2. 调用用户自定义初始化Init()
  if (!Init()) {
    AERROR << "Component Init() failed.";
    return false;
  }

  bool is_reality_mode = GlobalData::Instance()->IsRealityMode();

  ReaderConfig reader_cfg;
  reader_cfg.channel_name = config.readers(1).channel();
  reader_cfg.qos_profile.CopyFrom(config.readers(1).qos_profile());
  reader_cfg.pending_queue_size = config.readers(1).pending_queue_size();
  
  // 3. 创建reader1
  auto reader1 = node_->template CreateReader<M1>(reader_cfg);
  ...
  // 4. 创建reader0
  if (cyber_likely(is_reality_mode)) {
    reader0 = node_->template CreateReader<M0>(reader_cfg);
  } else {
    ...
  }
  
  readers_.push_back(std::move(reader0));
  readers_.push_back(std::move(reader1));


  auto sched = scheduler::Instance();
  // 5. 创建回调，回调执行Proc()
  std::weak_ptr<Component<M0, M1>> self =
      std::dynamic_pointer_cast<Component<M0, M1>>(shared_from_this());
  auto func = [self](const std::shared_ptr<M0>& msg0,
                     const std::shared_ptr<M1>& msg1) {
    auto ptr = self.lock();
    if (ptr) {
      ptr->Process(msg0, msg1);
    } else {
      AERROR << "Component object has been destroyed.";
    }
  };

  std::vector<data::VisitorConfig> config_list;
  for (auto& reader : readers_) {
    config_list.emplace_back(reader->ChannelId(), reader->PendingQueueSize());
  }
  // 6. 创建数据访问器
  auto dv = std::make_shared<data::DataVisitor<M0, M1>>(config_list);
  // 7. 创建协程，协程绑定回调func（执行proc）。数据访问器dv在收到订阅数据之后，唤醒绑定的协程执行任务，任务执行完成之后继续休眠。
  croutine::RoutineFactory factory =
      croutine::CreateRoutineFactory<M0, M1>(func, dv);
  return sched->CreateTask(factory, node_->Name());
}
```

<font color = "#dd0000" size = "5.5">小结：</font>

1. 创建node节点（1个component只能有1个node节点，用户可以用node_在init中自己创建reader或writer）。
2. 调用用户自定义的初始化函数Init()（子类的Init方法）
3. 创建reader，订阅几个消息就创建几个reader。
4. 创建回调函数，实际上是执行用户定义算法Proc()函数
5. 创建数据访问器，数据访问器的用途为接收数据（融合多个通道的数据），唤醒对应的协程执行任务。
6. 创建协程任务绑定回调函数，并且绑定数据访问器到对应的协程任务，用于唤醒对应的任务。

##### 2.4.6 创建协程

创建协程对应上述代码

```text
  croutine::RoutineFactory factory =
      croutine::CreateRoutineFactory<M0, M1>(func, dv);
```

协程通过工厂模式方法创建，里面包含一个回调函数和一个dv（数据访问器）

```cpp
template <typename M0, typename M1, typename F>
RoutineFactory CreateRoutineFactory(
    F&& f, const std::shared_ptr<data::DataVisitor<M0, M1>>& dv) {
  RoutineFactory factory;
  // 1. 工厂中设置DataVisitor
  factory.SetDataVisitor(dv);
  factory.create_routine = [=]() {
    return [=]() {
      std::shared_ptr<M0> msg0;
      std::shared_ptr<M1> msg1;
      for (;;) {
        CRoutine::GetCurrentRoutine()->set_state(RoutineState::DATA_WAIT);
        // 2. 从DataVisitor中获取数据
        if (dv->TryFetch(msg0, msg1)) {
          // 3. 执行回调函数
          f(msg0, msg1);
          // 4. 继续休眠
          CRoutine::Yield(RoutineState::READY);
        } else {
          CRoutine::Yield();
        }
      }
    };
  };
  return factory;
}
```

总结创建协程执行过程：

1. 工厂中设置DataVisitor
2. 工厂中创建设置协程执行函数，回调包括3个步骤：从DataVisitor中获取数据，执行回调函数，继续休眠.

##### 2.4.7 创建调度任务

创建调度任务是在过程"Component::Initialize"中完成。

```cpp
sched->CreateTask(factory, node_->Name());
```

在Scheduler中创建任务:

```cpp
bool Scheduler::CreateTask(std::function<void()>&& func,
                           const std::string& name,
                           std::shared_ptr<DataVisitorBase> visitor) {
  // 1. 根据名称创建任务ID
  auto task_id = GlobalData::RegisterTaskName(name);
  
  auto cr = std::make_shared<CRoutine>(func);
  cr->set_id(task_id);
  cr->set_name(name);
  AINFO << "create croutine: " << name;
  // 2. 分发协程任务
  if (!DispatchTask(cr)) {
    return false;
  }

  // 3. 注册Notify唤醒任务
  if (visitor != nullptr) {
    visitor->RegisterNotifyCallback([this, task_id]() {
      if (cyber_unlikely(stop_.load())) {
        return;
      }
      this->NotifyProcessor(task_id);
    });
  }
  return true;
}
```

##### 2.4.8 TimerComponent对象

Component分为2类：一类是为上述消息驱动的Component，第二类是定时调用的TimerComponent。定时调度模块没有绑定消息收发，需要用户自己创建reader来读取消息，如果需要读取多个消息，可以创建多个reader。

```cpp
bool TimerComponent::Initialize(const TimerComponentConfig& config) {
  // 1. 创建node
  node_.reset(new Node(config.name()));
  LoadConfigFiles(config);
  // 2. 调用用户自定义初始化函数
  if (!Init()) {
    return false;
  }

  std::shared_ptr<TimerComponent> self =
      std::dynamic_pointer_cast<TimerComponent>(shared_from_this());
  // 3. 创建定时器，定时调用"Proc()"函数
  auto func = [self]() { self->Proc(); };
  timer_.reset(new Timer(config.interval(), func, false));
  timer_->Start();
  return true;
}
```

总结TimerComponent的执行流程:

1. 创建Node
2. 调用用户自定义初始化函数
3. 创建定时器，定时调用"Proc()"函数

## 3.静态转换模块StaticTransfrom

用于相对于车身固定的传感器坐标系间实现静态转换，本项目涉及激光雷达部分转换树如下：

![image-20230606151404834](C:\Users\wuzailin\AppData\Roaming\Typora\typora-user-images\image-20230606151404834.png)

### 3.1 launch文件结构

```
    <module>
        <name>static_transform</name>
        <dag_conf>/zhito/modules/perception/launcher_perception/dag/static_transform.dag</dag_conf>
        <process_name>static_transform</process_name>
    </module>
```

### 3.2 dag文件结构

```
module_config {
    module_library : "/zhito/output/lib/libtransform_component.so"
    components {
        class_name : "StaticTransformComponent"
        config {
            name : "static_transform"
            config_file_path: "/zhito/modules/perception/launcher_perception/conf/static_transform_conf.pb.txt"
        }
    }
}
```

### 3.3 配置文件结构

```yaml
# 车身坐标系转换为惯导坐标系
extrinsic_file {
    frame_id: "novatel"
    child_frame_id: "vehicle"
    file_path: "/zhito/modules/perception/launcher_perception/params/vehicle_novatel_extrinsics.yaml"
    enable: true
}

# 主雷达坐标系转换为车身坐标系
extrinsic_file {
    frame_id: "vehicle"
    child_frame_id: "hesai40p"
    file_path: "/zhito/modules/perception/launcher_perception/params/hesai40_top_vehicle_extrinsics.yaml"
    enable: true
}

# 左补盲雷达坐标系转换为主雷达坐标系
extrinsic_file {
    frame_id: "hesai40p"
    child_frame_id: "rfans_front_left"
    file_path: "/zhito/modules/perception/launcher_perception/params/lidar16_front_left_novatel_extrinsics.yaml"
    enable: true
}

# 右补盲雷达坐标系转换为主雷达坐标系
extrinsic_file {
    frame_id: "hesai40p"
    child_frame_id: "rfans_front_right"
    file_path: "/zhito/modules/perception/launcher_perception/params/lidar16_front_right_novatel_extrinsics.yaml"
    enable: true
}
```

### 3.4 外参文件结构

这里以主激光雷达转换至车身外参文件为例

```yaml
header:
  stamp:
    secs: 1422601952
    nsecs: 288805456
  seq: 0
  # 父坐标系名称
  frame_id: vehicle
transform:
  # 平移参数，子坐标系原点在父坐标系中的相对位置
  translation:
    x: 3.9428
    y: 0.0
    z: 1.8 
  # 旋转参数，通过四元数表示，子坐标系相对于父坐标系的偏转
  rotation:
    x: 0
    y: 0
    z: -0.03
    w: 1
# 子坐标系名称
child_frame_id: hesai40p
```

### 3.5 Component实现

TransformComponent模块的入口在"static_transform_component.cc"和"static_transform_component.h"中,实现了"StaticTransformComponent"类

```cpp
class StaticTransformComponent final : public apollo::cyber::Component<> {
 public:
  StaticTransformComponent() = default;  // 构造函数
  ~StaticTransformComponent() = default; // 析构函数

 public:
  bool Init() override;  // 初始化函数

 private:
  void SendTransforms();  // 发送变换
  void SendTransform(const std::vector<TransformStamped>& msgtf);  //发送变换，参数为数组
  bool ParseFromYaml(const std::string& file_path, TransformStamped* transform);  // 从yaml中解析

  apollo::static_transform::Conf conf_;  // 配置文件
  std::shared_ptr<cyber::Writer<TransformStampeds>> writer_;  // cyber node写句柄
  TransformStampeds transform_stampeds_;  // 变换关系，在proto中定义
};
```

staticTransformComponent类具体的实现，首先是Init函数，是读取conf配置，发布"/tf_static"消息。

```cpp
bool StaticTransformComponent::Init() {
  // 读取配置
  if (!GetProtoConfig(&conf_)) {
    AERROR << "Parse conf file failed, " << ConfigFilePath();
    return false;
  }
  // 发布消息
  cyber::proto::RoleAttributes attr;
  attr.set_channel_name("/tf_static");
  attr.mutable_qos_profile()->CopyFrom(
      cyber::transport::QosProfileConf::QOS_PROFILE_TF_STATIC);
  // 注意这里的node_继承至apollo::cyber::Component
  writer_ = node_->CreateWriter<TransformStampeds>(attr);
  SendTransforms();
  return true;
}
```

SendTransforms()函数，主要就是遍历conf文件，判断extrinsic_file(实际上对应各种传感器的外参)是否使能，如果使能则根据提供的文件路径解析对应的转换关系"ParseFromYaml"，把转换关系添加到数组"tranform_stamped_vec"中，然后发送;

```cpp
void StaticTransformComponent::SendTransforms() {
  std::vector<TransformStamped> tranform_stamped_vec;
  // 遍历对应的文件，实际上对应各种传感器的外参
  for (auto& extrinsic_file : conf_.extrinsic_file()) {
    // 是否使能
    if (extrinsic_file.enable()) {
      AINFO << "Broadcast static transform, frame id ["
            << extrinsic_file.frame_id() << "], child frame id ["
            << extrinsic_file.child_frame_id() << "]";
      TransformStamped transform;
      // 解析yaml文件，获取转换，并且添加到数组中
      if (ParseFromYaml(extrinsic_file.file_path(), &transform)) {
        tranform_stamped_vec.emplace_back(transform);
      }
    }
  }
  // 发送对应的转换
  SendTransform(tranform_stamped_vec);
}
```

解析yaml文件:

```c++
bool StaticTransformComponent::ParseFromYaml(
    const std::string& file_path, TransformStamped* transform_stamped) {
  ...
  YAML::Node tf = YAML::LoadFile(file_path);
  try {
    // 读取yaml文件中的frame_id和child_frame_id
    transform_stamped->mutable_header()->set_frame_id(
        tf["header"]["frame_id"].as<std::string>());
    transform_stamped->set_child_frame_id(
        tf["child_frame_id"].as<std::string>());
    // translation 位置
    auto translation =
        transform_stamped->mutable_transform()->mutable_translation();
    translation->set_x(tf["transform"]["translation"]["x"].as<double>());
    translation->set_y(tf["transform"]["translation"]["y"].as<double>());
    translation->set_z(tf["transform"]["translation"]["z"].as<double>());
    // rotation 角度
    auto rotation = transform_stamped->mutable_transform()->mutable_rotation();
    rotation->set_qx(tf["transform"]["rotation"]["x"].as<double>());
    rotation->set_qy(tf["transform"]["rotation"]["y"].as<double>());
    rotation->set_qz(tf["transform"]["rotation"]["z"].as<double>());
    rotation->set_qw(tf["transform"]["rotation"]["w"].as<double>());
  } catch (...) {
    AERROR << "Extrinsic yaml file parse failed: " << file_path;
    return false;
  }
  return true;
}
```

发送转换关系：

```cpp
void StaticTransformComponent::SendTransform(
    const std::vector<TransformStamped>& msgtf) {
  for (auto it_in = msgtf.begin(); it_in != msgtf.end(); ++it_in) {
    bool match_found = false;
    int size = transform_stampeds_.transforms_size();

    // 如果child_frame_id重复，那么则覆盖对应的配置
    for (int i = 0; i < size; ++i) {
      if (it_in->child_frame_id() ==
          transform_stampeds_.mutable_transforms(i)->child_frame_id()) {
        auto it_msg = transform_stampeds_.mutable_transforms(i);
        *it_msg = *it_in;
        match_found = true;
        break;
      }
    }
    if (!match_found) {
      // 获取增加的指针地址，并且赋值
      auto ts = transform_stampeds_.add_transforms();
      *ts = *it_in;
    }
  }
  writer_->Write(std::make_shared<TransformStampeds>(transform_stampeds_));
}
```

即首先遍历conf，获取传感器的外参数文件路径，然后解析对应的yaml文件，并且发布到"/tf_static"。

## 4.基于聚类算法的激光雷达感知

聚类算法在激光雷达感知应用广泛，可用于障碍物识别、可行驶区域提取等，在室内检测时效果为优。

### 4.1 launch文件结构

```
    <module>
        <name>perception</name>
        <dag_conf>/zhito/modules/perception/production/dag/dag_lidar_detection.dag</dag_conf>
        <process_name>lidar_perception</process_name>
        <version>1.0.0</version>
    </module> 
```

### 4.2 dag文件结构

```
module_config {
    module_library : "/zhito/output/lib/libperception_component.so"
    # 实现激光雷达聚类算法的障碍物检测
    components {
        class_name : "LidarDetectionComponent"
        config {
            name : "lidar_detection"
            config_file_path : "/zhito/modules/perception/production/conf/perception/lidar/lidar_detection_conf.pb.txt"
            flag_file_path: "/zhito/modules/perception/production/conf/perception/perception_common.flag"
            readers:[
                {
                    channel: "/zhito/sensor/fusion/PointCloud2" 
                    pending_queue_size: 10
                }
            ]
        }
    }
    # 实现激光雷达障碍物检测结果输出
    components {
        class_name: "LidarOutputComponent"
        config {
        name: "LidarOutputComponent"
        readers {
                    channel: "/perception/inner/SegmentationObjects"
          }
      }
   }
}

```

### 4.3 配置文件结构

/modules/perception/launcher_perception/conf/lidar/lidar_detection_conf.pb.txt

```yaml
ground_filter_conf {
    sensor_height: 0.0 # 激光雷达高度
    general_max_slope: 5.0 # 整个地面的坡度阈值     
    local_max_slope: 8.0 # 同条射线上临近两点的坡度阈值        
    radial_divider_angle: 0.1 # 分隔线间的距离（rad）
    concentric_divider_distance: 0.5  # 同心分区之间的距离（米）
    min_height_threshold: 0.2 # 最小高度阈值    
    clipping_height: 2.2 # 裁剪高度，以雷达为原点裁剪以上的高度 
    min_point_distance: 0.2 # 最近的点云距离，滤掉车身周围点云
    reclass_distance_threshold: 0.2 # 重新分类点之间的距离

euclidean_cluster_conf{
    downsample_cloud: true # 体素网格过滤时是否降采样
    pose_estimation: false # 使用最小面积边界矩形估计簇的姿态
    leaf_size: 0.1 # 下采样体素网格大小
    cluster_size_min: 10 # 聚类的最少点数
    cluster_size_max: 10000 # 聚类的最多点数

    remove_ground: false # 是否去地面
    using_sensor_cloud: false # 是否用传感器点云
    use_diffnormals: false # 是否用法线差滤波
    clip_min_height: 0.2 # 裁剪的最小高度
    clip_max_height: 2.0 # 裁剪的最大高度

    keep_lanes: false # 是否滤除车道线外点云
    keep_lane_left_distance: 10 # 左车道线距离保持
    keep_lane_right_distance: 10 # 右车道线距离保持
    own_car_front_limit: 0.5 # 自车前方距离限制
    own_car_rear_limit: -0.5 # 自车后方距离限制

    own_car_left_limit: 0.4 # 自车左方距离限制
    own_car_right_limit: -0.4 # 自车右方距离限制
    max_boundingbox_side: 10 # 包络框大小阈值
    remove_points_upto: 0.0 # 距离少于某一阈值点云会被去除
    cluster_merge_threshold: 0.7 # 聚类簇间距离

    clustering_distance: 0.4 # 聚类公差
    use_gpu: false # 是否用GPU
}

lidar_detection_component_conf {
    sensor_name: "velodyne32"  # 传感器名称
    enable_hdmap: true # 是否使用高精地图
    lidar_query_tf_offset: 0 
     # 转换子坐标系名称
    lidar2novatel_tf2_child_frame_id: "vehicle" 
    # 输出topic
    output_channel_name: "/perception/inner/SegmentationObjects" 
}
```

### 4.4 Component实现

##### 4.4.1 lidar_detection_compontent

1.modules/perception/onboard/lcomponent/lidar/lidar_detection_compontent.cc

**Init:**初始化函数，对参数进行加载、节点创建以及对算法进行初始化等；

```c++
// 加载参数：/modules/perception/launcher_perception/conf/lidar/lidar_detection_conf.pb.txt
// 初始函数，完成参数加载，节点创建，topic定义
bool LidarDetectionComponent::Init() {
  // LidarDetectionComponentConfig comp_config;
  lidar::LidarDetectionConf comp_config;
  if (!GetProtoConfig(&comp_config)) {
    return false;
  }
  AINFO << comp_config.DebugString();
  lidar::RayGroundFilterConf ray_ground_filter_conf;
  ray_ground_filter_conf.sensor_height_ =
      comp_config.ground_filter_conf().sensor_height();
  ray_ground_filter_conf.general_max_slope_ =
      comp_config.ground_filter_conf().general_max_slope();
  ray_ground_filter_conf.local_max_slope_ =
      comp_config.ground_filter_conf().local_max_slope();
  ray_ground_filter_conf.radial_divider_angle_ =
      comp_config.ground_filter_conf().radial_divider_angle();
  ray_ground_filter_conf.concentric_divider_distance_ =
      comp_config.ground_filter_conf().concentric_divider_distance();
  ray_ground_filter_conf.min_height_threshold_ =
      comp_config.ground_filter_conf().min_height_threshold();
  ray_ground_filter_conf.clipping_height_ =
      comp_config.ground_filter_conf().clipping_height();
  ray_ground_filter_conf.min_point_distance_ =
      comp_config.ground_filter_conf().min_point_distance();
  ray_ground_filter_conf.reclass_distance_threshold_ =
      comp_config.ground_filter_conf().reclass_distance_threshold();

  lidar::EuclideanLidarClusterDetectConf eculidiean_cluster_conf;
  eculidiean_cluster_conf.downsample_cloud =
      comp_config.euclidean_cluster_conf().downsample_cloud();
  eculidiean_cluster_conf.pose_estimation =
      comp_config.euclidean_cluster_conf().pose_estimation();
  eculidiean_cluster_conf.leaf_size =
      comp_config.euclidean_cluster_conf().leaf_size();
  eculidiean_cluster_conf.cluster_size_min =
      comp_config.euclidean_cluster_conf().cluster_size_min();
  eculidiean_cluster_conf.cluster_size_max =
      comp_config.euclidean_cluster_conf().cluster_size_max();
  eculidiean_cluster_conf.remove_ground =
      comp_config.euclidean_cluster_conf().remove_ground();
  eculidiean_cluster_conf.using_sensor_cloud =
      comp_config.euclidean_cluster_conf().using_sensor_cloud();
  eculidiean_cluster_conf.use_diffnormals =
      comp_config.euclidean_cluster_conf().use_diffnormals();
  eculidiean_cluster_conf.clip_min_height =
      comp_config.euclidean_cluster_conf().clip_min_height();
  eculidiean_cluster_conf.clip_max_height =
      comp_config.euclidean_cluster_conf().clip_max_height();
  eculidiean_cluster_conf.keep_lanes =
      comp_config.euclidean_cluster_conf().keep_lanes();
  eculidiean_cluster_conf.keep_lane_left_distance =
      comp_config.euclidean_cluster_conf().keep_lane_left_distance();
  eculidiean_cluster_conf.keep_lane_right_distance =
      comp_config.euclidean_cluster_conf().keep_lane_right_distance();
  eculidiean_cluster_conf.own_car_front_limit =
      comp_config.euclidean_cluster_conf().own_car_front_limit();
  eculidiean_cluster_conf.own_car_rear_limit =
      comp_config.euclidean_cluster_conf().own_car_rear_limit();
  eculidiean_cluster_conf.own_car_left_limit =
      comp_config.euclidean_cluster_conf().own_car_left_limit();
  eculidiean_cluster_conf.own_car_right_limit =
      comp_config.euclidean_cluster_conf().own_car_right_limit();
  eculidiean_cluster_conf.max_boundingbox_side =
      comp_config.euclidean_cluster_conf().max_boundingbox_side();
  eculidiean_cluster_conf.remove_points_upto =
      comp_config.euclidean_cluster_conf().remove_points_upto();
  eculidiean_cluster_conf.cluster_merge_threshold =
      comp_config.euclidean_cluster_conf().cluster_merge_threshold();
  eculidiean_cluster_conf.clustering_distance =
      comp_config.euclidean_cluster_conf().clustering_distance();
  eculidiean_cluster_conf.use_gpu =
      comp_config.euclidean_cluster_conf().use_gpu();
  lidar_manager_ = std::make_shared<lidar::LidarManager>(
      ray_ground_filter_conf, eculidiean_cluster_conf);

  ADEBUG << "Lidar Component Configs: " << comp_config.DebugString();
  output_channel_name_ =
      comp_config.lidar_detection_component_conf().output_channel_name();
  sensor_name_ = comp_config.lidar_detection_component_conf().sensor_name();
  lidar2novatel_tf2_child_frame_id_ =
      comp_config.lidar_detection_component_conf()
          .lidar2novatel_tf2_child_frame_id();
  lidar_query_tf_offset_ = static_cast<float>(
      comp_config.lidar_detection_component_conf().lidar_query_tf_offset());
  enable_hdmap_ = comp_config.lidar_detection_component_conf().enable_hdmap();
  // odometry_channel_name_ =
  // comp_config.lidar_detection_component_conf().odometry_channel_name();
  writer_ = node_->CreateWriter<SensorFrameMessage>(output_channel_name_);

  point_groundless_writer_ = node_->CreateWriter<PointCloud>(
      "/zhito/sensor/rfans16/front/left/groundless/PointCloud2");
  point_cloud_pool_.reset(new CCObjectPool<PointCloud>(pool_size_));
  point_cloud_pool_->ConstructAll();
  for (int i = 0; i < pool_size_; i++) {
    auto point_cloud = point_cloud_pool_->GetObject();
    if (point_cloud == nullptr) {
      AERROR << "fail to getobject, i: " << i;
      return false;
    }
    point_cloud->mutable_point()->Reserve(140000);
  }


  if (!InitAlgorithmPlugin()) {
    AERROR << "Failed to init detection component algorithm plugin.";
    return false;
  }

  std::string odometry_channel_name_ = "/zhito/localization/pose";
  localization_subscriber_.Init(odometry_channel_name_,
                                odometry_channel_name_ + '_' + sensor_name_);

  return true;
}
```

**Proc:**进行算法执行，并输出处理结果；

```cpp
// 算法执行，并输出处理结果
bool LidarDetectionComponent::Proc(
    const std::shared_ptr<drivers::PointCloud>& message) {
  AINFO << "\n\n---------------------------------------------------------------"
           "------";

  std::shared_ptr<SensorFrameMessage> out_message(new (std::nothrow)
                                                      SensorFrameMessage);

  //此处进行算法执行  
  bool status = InternalProc(message, out_message);
  if (status) {
    writer_->Write(out_message);
    AINFO << "Send lidar detect output message.";
  }
  return status;
}
```

**InteralProc:**算法载入函数，通过调用AlgothrimProcess()函数进入算法实际执行；

```cpp
// 算法核心处理部分
bool LidarDetectionComponent::InternalProc(
    const std::shared_ptr<const drivers::PointCloud>& in_message,
    const std::shared_ptr<SensorFrameMessage>& out_message) {
  PERCEPTION_PERF_FUNCTION_WITH_INDICATOR(sensor_name_);
  {
    std::unique_lock<std::mutex> lock(s_mutex_);
    s_seq_num_++;
  }

  const double timestamp = in_message->measurement_time();
  const double cur_time = zhito::common::time::Clock::NowInSeconds();
  const double start_latency = (cur_time - timestamp) * 1e3;
  AINFO << "FRAME_STATISTICS:Lidar:Start:msg_time[" << timestamp << sensor_name_
        << ":Start:msg_time["
        << "]:cur_time[" << cur_time << "]:cur_latency[" << start_latency
        << "]";

  out_message->timestamp_ = timestamp;
  out_message->lidar_timestamp_ = in_message->header().lidar_timestamp();

  AINFO << "timestamp_" << out_message->timestamp_;
  AINFO << "lidar_timestamp_" << out_message->lidar_timestamp_;

  out_message->seq_num_ = s_seq_num_;
  out_message->process_stage_ = ProcessStage::LIDAR_DETECTION;
  out_message->error_code_ = zhito::common::ErrorCode::OK;
  out_message->sensor_id_ = sensor_name_;

  PERCEPTION_PERF_BLOCK_START();
  Eigen::Affine3d pose = Eigen::Affine3d::Identity();
  const double lidar_query_tf_timestamp =
      timestamp - lidar_query_tf_offset_ * 0.001;
  if (!lidar2world_trans_.GetSensor2worldTrans(lidar_query_tf_timestamp,
                                               &pose)) {
    out_message->error_code_ = zhito::common::ErrorCode::PERCEPTION_ERROR_TF;
    AERROR << "Failed to get pose at time: " << lidar_query_tf_timestamp;
    return false;
  }
  auto& frame = out_message->frame_;
  frame = base::FramePool::Instance().Get();
  // frame->cloud = base::PointFCloudPool::Instance().Get();
  frame->timestamp = timestamp;
  frame->sensor_info = sensor_info_;
  frame->sensor2world_pose = pose;
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(
      sensor_name_, "detection_1::get_lidar_to_world_pose");

  lidar::LidarObstacleDetectionOptions detect_opts;
  detect_opts.sensor_name = sensor_name_;
  lidar2world_trans_.GetExtrinsics(&detect_opts.sensor2novatel_extrinsics)

  lidar::LidarPerceptionOptions options;
  options.sensor_name = sensor_name_;
  options.detector_options.lidar2world_pose = &pose.matrix();
  if (!GetCarLocalizationSpeed(timestamp,
                               &(options.detector_options.car_linear_speed),
                               &(options.detector_options.car_angular_speed))) {
    AERROR << std::fixed
           << "Failed to call get_car_speed. [timestamp: " << timestamp;
    return false;
  }


  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name_, "GetCarSpeed");
  
  //根据输入数据，进入具体处理函数
  AlgothrimProcess(in_message);

  // output the tracking obstacles to funsion in sensorFrame message.
  UpdateMessage(frame);

  CalcAttributeForLocal(frame->sensor2world_pose, options.detector_options,
                        frame);

  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name_,
                                           "detection_2::detect_obstacle");

  return true;
}
```

**AlgothrimProcess()**:具体处理函数，通过lidar_manager_->Run(in_message, tracker_objects)进入算法处理调度

```cpp
bool LidarDetectionComponent::AlgothrimProcess(
    const std::shared_ptr<const drivers::PointCloud>& in_message) {
  // 以上省略
  // 调用Run函数，进入算法调度
  current_groundless_cloud_ptr =
      lidar_manager_->Run(in_message, tracker_objects);
  //以下省略
}
```

2./modules/perception/lidar/lib/perception_lidar/lidar_manager/lidar_manager.cc

**Run():**调度函数，以此执行预处理、去地面、聚类、障碍物追踪、结果输出等；

```cpp
pcl::PointCloud<pcl::PointXYZ>::Ptr LidarManager::Run(const std::shared_ptr<zhito::drivers::PointCloud const>& message,DetectedObjectArray& output_detected_objects) {
  // std::shared_ptr<PointCloud> point_cloud_out;
  current_cloud.clear();
  current_ground_cloud.clear();
  current_groundless_cloud.clear();

  pcl::PointCloud<pcl::PointXYZ>::Ptr current_cloud_ptr(new pcl::PointCloud<pcl::PointXYZ>);
  pcl::PointCloud<pcl::PointXYZ>::Ptr current_ground_cloud_ptr(new pcl::PointCloud<pcl::PointXYZ>);
  pcl::PointCloud<pcl::PointXYZ>::Ptr current_groundless_cloud_ptr(new pcl::PointCloud<pcl::PointXYZ>);
  pcl::PointCloud<pcl::PointXYZ>::Ptr current_total_cluster_cloud_ptr(new pcl::PointCloud<pcl::PointXYZ>);
  current_cloud_ptr = current_cloud.makeShared();
  current_ground_cloud_ptr = current_ground_cloud.makeShared();
  current_groundless_cloud_ptr = current_groundless_cloud.makeShared();

  Preprocess(message, current_cloud_ptr);

  // first step: remove ground pointcloud
  ground_filter_.Run(current_cloud_ptr, current_groundless_cloud_ptr, current_ground_cloud_ptr);

  // for cluster
  DetectedObjectArray detected_objects;
  euclidean_cluster_detector.Run(current_groundless_cloud_ptr, detected_objects);

  std::cout << "[lidar_manager] detected obs size: " << detected_objects.objects.size() << std::endl;
  for (unsigned int i = 0; i < detected_objects.objects.size(); i++) {
    pcl::PointXYZ point;
    for (unsigned int j = 0; j < detected_objects.objects[i].pointcloud.size(); j++) {
      point.x = detected_objects.objects[i].pointcloud[j].x;
      point.y = detected_objects.objects[i].pointcloud[j].y;
      point.z = detected_objects.objects[i].pointcloud[j].z;
      current_total_cluster_cloud_ptr->points.push_back(point);
    }
  }

  // DetectedObjectArray tracker_objects;
  tracker_manger.Run(detected_objects, output_detected_objects);

  // last step: output tracker_objects to channel
  return current_total_cluster_cloud_ptr;
  return current_groundless_cloud_ptr;
}
```

最后通过不同步骤的执行函数进入到不同的执行区域，其操作可查看具体代码

##### 4.4.2 lidar_output_component

/module/percrption/onboard/component/lidar_output_component.cc

**Init(),Proc():**初始化函数，创建节点，加载数据并输出到topic：/zhito/perception/obstacles

```cpp
bool LidarOutputComponent::Init() {
  //创建节点与writer
  writer_ = node_->CreateWriter<PerceptionObstacles>("/zhito/perception/obstacles");
  return true;
}

bool LidarOutputComponent::Proc(const std::shared_ptr<SensorFrameMessage>& message) {
  //检查数据，并将其输出给对应的Channel
  std::shared_ptr<PerceptionObstacles> out_message(new PerceptionObstacles);

  if (message->frame_ == nullptr) {
    AERROR << "Failed to get frame in message.";
    return false;
  }

  if (!MsgSerializer::SerializeMsg(message->timestamp_, message->lidar_timestamp_, message->seq_num_, message->frame_->objects,
                                   message->error_code_, out_message.get())) {
    AERROR << "Failed to serialize PerceptionObstacles object.";
    return false;
  }

  writer_->Write(out_message);
  // Send("/zhito/perception/obstacles", out_message);

  return true;
}
```

## 5.基于CNNSeg算法的激光雷达感知

### 5.1 launch文件结构

```
<module>
   <name>obstacle_perception</name>
   <dag_conf>/zhito/modules/perception/launcher_perception/dag/obstacle_perception.dag</dag_conf>           
   <process_name>obstacle_perception</process_name>
   <version>1.0.0</version>
</module> 
```

### 5.2 dag文件结构

```
 components {
    class_name : "SegmentationComponent"
    config {
      name: "Velodyne32Segmentation"
      config_file_path: "/zhito/modules/perception/launcher_perception/conf/lidar/velodyne32_segmentation_conf.pb.txt"
      flag_file_path: "/zhito/modules/perception/launcher_perception/conf/perception_common.flag"
      readers {
          channel: "/zhito/sensor/fusion/PointCloud2"
        }
    }
 }

  components {
    class_name : "RecognitionComponent"
    config {
      name: "RecognitionComponent"
      config_file_path: "/zhito/modules/perception/launcher_perception/conf/lidar/velodyne32_recognition_conf.pb.txt"
      readers {
          channel: "/perception/inner/SegmentationObjects"
        }
    }
  }
```

### 5.3 配置文件结构

1. 分割组件（SegmentationComponent）配置文件

/modules/perception/launcher_perception/conf/lidar/velodyne32_segmentation_conf.pb.txt

```yaml
sensor_name: "velodyne32" #传感器名称
enable_hdmap: true #是否使用高精地图
lidar_query_tf_offset: 0 
#转换子坐标系名称
lidar2novatel_tf2_child_frame_id: "vehicle" 
#输出topic
output_channel_name: "/perception/inner/SegmentationObjects"
```

2. 障碍物检测算法指定文件（pipline）

/modules/perception/launcher_perception/data/lidar/modules/lidar_obstacle_pipline/velodyne32/lidar_obstacles_segmentation.conf

```yaml
segmentor: "CNNSegmentation" #使用的检测算法
use_map_manager: true
use_object_filter_bank: true
```

3. 点云预处理配置文件

/modules/perception/launcher_perception/data/lidar/modules/pointcloud_preprocessor/velodyne32/pointcloud_preprocessor.conf

```yaml
#是否滤除值为nan或inf的点
filter_naninf_points: true
#是否滤除近处（自车）点云
filter_nearby_box_points: true
#自车点云去除范围
box_forward_x: 4.8
box_backward_x: -1.2
box_forward_y: 1.3
box_backward_y: -1.3
#是否滤除过高的点
filter_high_z_points: true
#点云高度阈值，高于此阈值则被滤除
z_threshold: 2.0
# 是否滤除过远的点
filter_region: true
#范围以外的点滤除范围
range_forward_x: 250.0
range_backward_x: -250.0
range_forward_y: 40.0
range_backward_y: -40.0
trailer_existed: false
max_in_box_number: 5
```

4. CNNSeg模型配置文件

   modules/perception/launcher_perception/data/lidar/models/cnnseg/velodyne32/cnnseg_param.conf

```yaml
objectness_thresh: 0.5 #用于在障碍物聚类步骤中过滤掉非对象单元对象的阈值
confidence_thresh: 0.1 #用于在后期处理过程中滤出候选聚类的检测置信度得分阈值
confidence_range: 58.0 #相对于原点（激光雷达传感器）的置信范围，用于高质量检测
height_thresh: 0.5 #如果是非负数，则在后处理步骤中将过滤掉高于预测物体高度的点
min_pts_num: 3 #在后期处理中，删除具有小于min_pts_num点的候选集群
model_type: "RTNet"  #神经网络类型，RTNet代表TensorRT加速网络

gpu_id: 0 #在基于CNN的障碍物预测步骤中使用的GPU设备的ID

ground_detector: "SpatioTemporalGroundDetector" #地面检测器类型
roi_filter: "HdmapROIFilter" #ROI感兴趣区域提取器类型
remove_ground_points: false #是否去除地面点
fill_recall_with_ncut: false #是否融合NCut检测算法
ncut_with_roi: false #NCut算法是否在感兴趣区域中进行

#基于Caffe框架下的神经网络输入输出层类别
network_param {
    instance_pt_blob: "instance_pt"
    category_pt_blob: "category_score"
    confidence_pt_blob: "confidence_score"
    height_pt_blob: "height_pt"
    heading_pt_blob: "heading_pt"
    class_pt_blob: "class_score"
    feature_blob: "data"
}

feature_param {
    width: 672 #2D网格的X轴上的单元格数
    height: 672 #2D网格的Y轴上的单元格数
    point_cloud_range: 70 #2D格栅相对于原点（LiDAR传感器）的范围
    min_height: -5.0 #相对于原点的最小高度
    max_height: 5.0 #相对于原点的最大高度
    use_intensity_feature: true #是否使用强度特征
    use_constant_feature: false #是否使用固定特征
}
```

### 5.4 Component实现

1.segmentation_component

/modules/perception/onboard/compoment/segmentation_component.cc

**Init():**读取配置文件，做一些变量初始化命名，创建writer结点，再初始化算法插件:

```cpp
//加载参数/modules/perception/launcher_perception/conf/lidar/velodyne32_segmentation_conf.pb.txt
//output_channel_name:输出信道名称
//sensor_name_：传感器名称
//lidar2novatel_tf2_child_frame_id_：massage frame id
bool SegmentationComponent::Init() {
  comp_config;
  if (!GetProtoConfig(&comp_config)) {
    return false;
  }
  AINFO << "Lidar Component Configs: " << comp_config.DebugString();
  ADEBUG << "Lidar Component Configs: " << comp_config.DebugString();
  output_channel_name_ = comp_config.output_channel_name();
  sensor_name_ = comp_config.sensor_name();
  lidar2novatel_tf2_child_frame_id_ = comp_config.lidar2novatel_tf2_child_frame_id();
  lidar_query_tf_offset_ = static_cast<float>(comp_config.lidar_query_tf_offset());
  enable_hdmap_ = comp_config.enable_hdmap();
  writer_ = node_->CreateWriter<LidarFrameMessage>(output_channel_name_);
  pub_writer_ = node_->CreateWriter<PerceptionObstacles>("/zhito/perception/obstacles");
  #if VISUALIZARION_DEBUG
    pub_cnnseg_perception_obstacles_ = node_->CreateWriter<PerceptionObstacles>("/zhito/perception/obstacles/cnnseg");
    pub_ncut_perception_obstacles_ = node_->CreateWriter<PerceptionObstacles>("/zhito/perception/obstacles/ncut");
  #endif

  point_cloud_pool_.reset(new CCObjectPool<PointCloud>(pool_size_));
  point_cloud_pool_->ConstructAll();
  for (int i = 0; i < pool_size_; i++) {
    auto point_cloud = point_cloud_pool_->GetObject();
    if (point_cloud == nullptr) {
      AERROR << "fail to getobject, i: " << i;
      return false;
    }
    point_cloud->mutable_point()->Reserve(140000);
  }

#ifdef PUB_LIDAR_SEGMENTATION
  pub_writer_ = node_->CreateWriter<PerceptionObstacles>("/zhito/perception/segment");
#endif

  if (!InitAlgorithmPlugin()) {
    AERROR << "Failed to init segmentation component algorithm plugin.";
    return false;
  }
  return true;
}
```

**Proc**():新建一个writer结点写到channel里的out_message，调用InternalProc()函数，并将该函数处理的结果写入channel:

```cpp
bool SegmentationComponent::Proc(const std::shared_ptr<drivers::PointCloud>& message) {
  // AINFO << "Enter segmentation component, message timestamp: " << message->measurement_time()
  //       << " current timestamp: " << zhito::common::time::Clock::NowInSeconds();

  std::shared_ptr<LidarFrameMessage> out_message(new (std::nothrow) LidarFrameMessage);
  std::shared_ptr<PerceptionObstacles> pub_message(new (std::nothrow) PerceptionObstacles);

  bool status = InternalProc(message, out_message); // 算法执行函数

#ifdef PUB_LIDAR_SEGMENTATION
  bool trans_succ = TransformMessage(out_message, pub_message);
#endif
  
  if (status) {
    writer_->Write(out_message);
#ifdef PUB_LIDAR_SEGMENTATION
    if (trans_succ) {
      pub_writer_->Write(pub_message);
    }
#endif
    
  }

  std::shared_ptr<SensorFrameMessage> sensor_frame_message(new (std::nothrow) SensorFrameMessage);

  return status;
}
```

**InternalProc()：算法执行函数，主要进行变量更新以及进入激光雷达识别算法执行调度

```cpp
//该函数在前半段主要是做一些变量的更新（时间戳，out_message更新等）
//然后计算了传感器（激光雷达）到障碍物的坐标变换矩阵、传感器（激光雷达）到novatel的坐标变换矩阵，所有矩阵存储在变量lidar2world_trans_中
//最后调用了segmentor_的Process方法，进入激光雷达分割（lidar_obstacle_segmentation.cc）

bool SegmentationComponent::InternalProc(const std::shared_ptr<const drivers::PointCloud>& in_message,
                                         const std::shared_ptr<LidarFrameMessage>& out_message) {
  std::shared_ptr<PointCloud> point_cloud_out = point_cloud_pool_->GetObject();
  if (point_cloud_out == nullptr) {
    AWARN << "poin cloud pool return nullptr, will be create new.";
    point_cloud_out = std::make_shared<PointCloud>();
    point_cloud_out->mutable_point()->Reserve(140000);
  }
  if (point_cloud_out == nullptr) {
    AWARN << "point cloud out is nullptr";
    return false;
  }
  point_cloud_out->Clear();
  point_cloud_out->mutable_header()->set_frame_id(in_message->header().frame_id());
  point_cloud_out->mutable_header()->set_timestamp_sec(static_cast<double>(in_message->measurement_time()));
  point_cloud_out->mutable_header()->set_module_name("lidar");
  point_cloud_out->mutable_header()->set_sequence_num(in_message->header().sequence_num());
  point_cloud_out->set_height(1);
  point_cloud_out->set_measurement_time(static_cast<double>(in_message->measurement_time()));
  point_cloud_out->set_frame_id(in_message->header().frame_id());
  point_cloud_out->set_is_dense(true);

  PERCEPTION_PERF_FUNCTION_WITH_INDICATOR(sensor_name_);
  {
    std::unique_lock<std::mutex> lock(s_mutex_);
    s_seq_num_++;
  }

  //时间戳获取、比对与检验
  const double timestamp = in_message->header().timestamp_sec();
  const double cur_time = zhito::common::time::Clock::NowInSeconds();
  const double start_latency = (cur_time - timestamp) * 1e3;
  // AINFO << std::fixed << "FRAME_STATISTICS:Lidar:Start:msg_time[" << timestamp << sensor_name_ << ":Start:msg_time["
  //       << "]:cur_time[" << cur_time << "]:cur_latency[" << start_latency << "]";

//定义out_message，file:modules\perception\onboard\component\lidar_inner_component_messages.h
  out_message->timestamp_ = timestamp;
  out_message->lidar_timestamp_ = in_message->header().lidar_timestamp();
  out_message->seq_num_ = s_seq_num_;
  out_message->process_stage_ = ProcessStage::LIDAR_SEGMENTATION;
  out_message->error_code_ = zhito::common::ErrorCode::OK;

//定义frame
  auto& frame = out_message->lidar_frame_;
  frame = lidar::LidarFramePool::Instance().Get();
  frame->cloud = base::PointFCloudPool::Instance().Get();
  frame->timestamp = timestamp;
  frame->sensor_info = sensor_info_;

//获取时间戳
  PERCEPTION_PERF_BLOCK_START();
  Eigen::Affine3d pose = Eigen::Affine3d::Identity();
  Eigen::Affine3d pose_novatel = Eigen::Affine3d::Identity();
  const double lidar_query_tf_timestamp = timestamp - lidar_query_tf_offset_ * 0.001;
  if (!lidar2world_trans_.GetSensor2worldTrans(lidar_query_tf_timestamp, &pose, &pose_novatel)) {
    out_message->error_code_ = zhito::common::ErrorCode::PERCEPTION_ERROR_TF;
    AERROR << "Failed to get pose at time: " << lidar_query_tf_timestamp;
    return false;
  }
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name_, "segmentation_1::get_lidar_to_world_pose");

  frame->lidar2world_pose = pose;
  frame->novatel2world_pose = pose_novatel;

//调用segmentor_的process函数，进入modules\perception\lidar\app\lidar_obstacle_segmentation.cc
  lidar::LidarObstacleSegmentationOptions segment_opts;
  segment_opts.sensor_name = sensor_name_;
  lidar2world_trans_.GetExtrinsics(&segment_opts.sensor2novatel_extrinsics);
  lidar::LidarProcessResult ret = segmentor_->Process(segment_opts, in_message, frame.get());


  #if VISUALIZARION_DEBUG
    publishPerceptionObstacles(pub_cnnseg_perception_obstacles_, frame->segmented_objects, base::LidarAlgorithmType::CNNSeg);
    publishPerceptionObstacles(pub_ncut_perception_obstacles_, frame->segmented_objects, base::LidarAlgorithmType::NCut);
  #endif
  if (ret.error_code != lidar::LidarErrorCode::Succeed) {
    out_message->error_code_ = zhito::common::ErrorCode::PERCEPTION_ERROR_PROCESS;
    AERROR << "Lidar segmentation process error, " << ret.log;
    return false;
  }

  // PointCloudVisvualization(point_cloud_out, frame.get());

  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name_, "segmentation_2::segment_obstacle");

  return true;
}
```

2.激光雷达障碍物检测组织程序

modules/perception/lidar/app/lidar_obstacle_segmentation.cc

**Init**：读取配置文件参数并初始化

```cpp
//配置文件地址：
//modules/perception/launcher_perception/data/lidar/modules/lidar_obstacle_pipline/velodyne32/lidar_obstacles_segmentation.conf
bool LidarObstacleSegmentation::Init(const LidarObstacleSegmentationInitOptions& options) {
  auto& sensor_name = options.sensor_name;
  auto config_manager = lib::ConfigManager::Instance();
  const lib::ModelConfig* model_config = nullptr;
  ACHECK(config_manager->GetModelConfig(Name(), &model_config));

  const std::string work_root = config_manager->work_root();
  std::string config_file;
  std::string root_path;
  ACHECK(model_config->get_value("root_path", &root_path));
  config_file = cyber::common::GetAbsolutePath(work_root, root_path);
  config_file = cyber::common::GetAbsolutePath(config_file, sensor_name);
  config_file = cyber::common::GetAbsolutePath(config_file, "lidar_obstacle_segmentation.conf");

  LidarObstacleSegmentationConfig config;
  ACHECK(cyber::common::GetProtoFromFile(config_file, &config));
  segmentor_name_ = config.segmentor();
  use_map_manager_ = config.use_map_manager();
  use_object_filter_bank_ = config.use_object_filter_bank();

  AINFO << " segmentor_name_: " << segmentor_name_.c_str();
  AINFO << " use_map_manager_: " << use_map_manager_;
  AINFO << " use_object_filter_bank_: " << use_object_filter_bank_;

  use_map_manager_ = use_map_manager_ && options.enable_hdmap_input;

  SceneManagerInitOptions scene_manager_init_options;
  ACHECK(SceneManager::Instance().Init(scene_manager_init_options));

  PointCloudPreprocessorInitOptions preprocessor_init_options;
  preprocessor_init_options.sensor_name = sensor_name;
  ACHECK(cloud_preprocessor_.Init(preprocessor_init_options));

  if (use_map_manager_) {
    MapManagerInitOptions map_manager_init_options;
    if (!map_manager_.Init(map_manager_init_options)) {
      AINFO << "Failed to init map manager.";
      use_map_manager_ = false;
    }
  }

  segmentor_.reset(BaseSegmentationRegisterer::GetInstanceByName(segmentor_name_));
  CHECK_NOTNULL(segmentor_.get());
  SegmentationInitOptions segmentation_init_options;
  segmentation_init_options.sensor_name = sensor_name;
  ACHECK(segmentor_->Init(segmentation_init_options));

  ObjectBuilderInitOptions builder_init_options;
  ACHECK(builder_.Init(builder_init_options));

  if (use_object_filter_bank_) {
    ObjectFilterInitOptions filter_bank_init_options;
    filter_bank_init_options.sensor_name = sensor_name;
    ACHECK(filter_bank_.Init(filter_bank_init_options));
  }

  return true;
}
```

**Process：**算法执行处理函数，执行点云预处理和算法主体部分

```cpp
//key:执行ProcessCommon()
LidarProcessResult LidarObstacleSegmentation::Process(const LidarObstacleSegmentationOptions& options,
                                                      const std::shared_ptr<zhito::drivers::PointCloud const>& message, LidarFrame* frame) {
  const auto& sensor_name = options.sensor_name;

  PERCEPTION_PERF_FUNCTION_WITH_INDICATOR(options.sensor_name);

  PERCEPTION_PERF_BLOCK_START();
  PointCloudPreprocessorOptions preprocessor_options;
  preprocessor_options.sensor2novatel_extrinsics = options.sensor2novatel_extrinsics;
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name, "preprocess");
  // Preprocess():点云预处理
  if (cloud_preprocessor_.Preprocess(preprocessor_options, message, frame)) {
    // ProcessCommon()：执行算法主体
    return ProcessCommon(options, frame);  
  }
  return LidarProcessResult(LidarErrorCode::PointCloudPreprocessorError, "Failed to preprocess point cloud.");
}
```

**ProcessCommon:**算法主体部分实现函数

```cpp
//key:执行Segment()
LidarProcessResult LidarObstacleSegmentation::ProcessCommon(const LidarObstacleSegmentationOptions& options, LidarFrame* frame) {
  const auto& sensor_name = options.sensor_name;

  PERCEPTION_PERF_BLOCK_START();
  if (use_map_manager_) {
    MapManagerOptions map_manager_options;
    // Updata():获取高精地图信息
    if (!map_manager_.Update(map_manager_options, frame)) {
      return LidarProcessResult(LidarErrorCode::MapManagerError, "Failed to update map structure.");
    }
  }
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name, "map_manager");

  SegmentationOptions segmentation_options;
  // Segment():进行CNNSeg算法中特征提取、网络推理、聚类等步骤
  if (!segmentor_->Segment(segmentation_options, frame)) {
    return LidarProcessResult(LidarErrorCode::SegmentationError, "Failed to segment.");
  }
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name, "segmentation");

  ObjectBuilderOptions builder_options;
  // Build():进行障碍物目标构建
  if (!builder_.Build(builder_options, frame)) {
    return LidarProcessResult(LidarErrorCode::ObjectBuilderError, "Failed to build objects.");
  }
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name, "object_builder");

  ObjectFilterOptions filter_options;
  // Filter():进行障碍物目标筛选
  if (!filter_bank_.Filter(filter_options, frame)) {
    return LidarProcessResult(LidarErrorCode::ObjectFilterError, "Failed to filter objects.");
  }
  PERCEPTION_PERF_BLOCK_END_WITH_INDICATOR(sensor_name, "filter_bank");

  return LidarProcessResult(LidarErrorCode::Succeed);
}
```

3.CNNSeg算法主体实现部分

/modules/perception/lidar/lib/segmentation/cnnseg/cnn_segmentation.cc

**Init:**初始化函数，读取配置文件及参数以及对具体模型进行初始化

```cpp
bool CNNSegmentation::Init(const SegmentationInitOptions& options) {
  //配置文件地址：
  // publisher
  #if CNN_VISUALIZATION
    node_ = zhito::cyber::CreateNode("cnn_segmentataion");
    pub_ground_cut_cloud_ = node_->CreateWriter<PointCloud>("/zhito/perception/lidar/ground_cut/cnnseg");
    pub_cluster_point_cloud_ = node_->CreateWriter<PointCloud>("/zhito/perception/lidar/cluster/cloud");
    pub_polygons_road_ = node_->CreateWriter<Polygons>("/zhito/perception/lidar/road_polygons");
    pub_polygons_junction_ = node_->CreateWriter<Polygons>("/zhito/perception/lidar/junction_polygons");
    pub_polygons_hole_ = node_->CreateWriter<Polygons>("/zhito/perception/lidar/hole_polygons");
  #endif
  // get configs --加载CNNseg模型配置文件
  std::string param_file;
  std::string proto_file;
  std::string weight_file;
  std::string engine_file;
  sensor_name_ = options.sensor_name;
  ACHECK(GetConfigs(&param_file, &proto_file, &weight_file, &engine_file));
  AINFO << "--    param_file: " << param_file;
  AINFO << "--    proto_file: " << proto_file;
  AINFO << "--    weight_file: " << weight_file;
  AINFO << "--    engine_file: " << engine_file;

  /*获取CNN分割参数和SPP(分割点云处理器)引擎参数
   *CNN负责对2D图像上的每个单元格进行分类预测，方向预测
   *SPP通过聚类算法把单元格进行聚类*/
  // get cnnseg params
  ACHECK(GetProtoFromFile(param_file, &cnnseg_param_)) << "Failed to parse CNNSegParam config file." << param_file;
  ACHECK(GetProtoFromFile(engine_file, &spp_engine_config_)) << "Failed to parse SppEngine config file." << engine_file;

  //width_和height_是点云映射成2D索引图point2grid_的宽度和高度，range_是点云的最远距离
  //range_:点云的有效范围
  //width_；height_:所有点云最终映射到2D图像的宽度和高度
  //min_height_;max_height_:点云的有效高度，lidar距地面有一定高度
  // init feature parameters
  const FeatureParam& feature_param = cnnseg_param_.feature_param();
  range_ = feature_param.point_cloud_range();  //70
  width_ = feature_param.width();    //672
  height_ = feature_param.height();  //672
  min_height_ = feature_param.min_height();  //-5
  max_height_ = feature_param.max_height();  //5

//初始化推测模型；
//网络模型在data/perception/lidar/models/cnnseg/velodyne64/deploy.prototxt 
//网络输入input_names为data，为形状[1,6,672,672]的2D索引图point2grid_，其中6个通道依次存放的数据为point2grid_中每一格的数据：
//max_height_data_：映射到此单元格的所有点云的最大高度；
//mean_height_data_：映射到此单元格的所有点云的平均高度；
//count_data_：映射到此单元格的所有点云的数量；
//nonempty_data_：表明此单元格非空；
//top_intensity_data_：映射到此单元格的所有点云的最大强度，强度有助于判断物体；
//mean_intensity_data_：映射到此单元格的所有点云的平均强度；
//上面的特征数据是由feature_generator_提取的；
 
//网络的输出为反卷集deconv0，形状为[1,12,672,672]，其中12个通道为如下数据：
//category_pt：0，表示属于什么类型；
//instance_pt：1-2，中心点的位置r,c；
//confidence_pt：3，置信度；
//classify_pt：4-8，属于某种分类的概率(人、大车、小车、自行车、其他)；
//heading_pt：9-10，方向；
//height_pt：11，高度

  // init inference model
  const NetworkParam& network_param = cnnseg_param_.network_param();
  std::vector<std::string> output_names;
  output_names.push_back(network_param.instance_pt_blob());
  output_names.push_back(network_param.category_pt_blob());
  output_names.push_back(network_param.confidence_pt_blob());
  output_names.push_back(network_param.height_pt_blob());
  output_names.push_back(network_param.heading_pt_blob());
  output_names.push_back(network_param.class_pt_blob());
  std::vector<std::string> input_names;
  input_names.push_back(network_param.feature_blob());
  inference_.reset(inference::CreateInferenceByName(cnnseg_param_.model_type(), proto_file, weight_file, output_names, input_names));
  CHECK_NOTNULL(inference_.get());

  gpu_id_ = cnnseg_param_.has_gpu_id() ? cnnseg_param_.gpu_id() : -1;
  BASE_CUDA_CHECK(cudaSetDevice(gpu_id_));
  inference_->set_gpu_id(gpu_id_);  // inference sets CPU mode when -1

  std::map<std::string, std::vector<int>> input_shapes;
  auto& input_shape = input_shapes[network_param.feature_blob()];
  input_shape = {1, 8, height_, width_};
  if (!feature_param.use_intensity_feature()) {
    input_shape[1] -= 2;
  }
  if (!feature_param.use_constant_feature()) {
    input_shape[1] -= 2;
  }
  ACHECK(inference_->Init(input_shapes)) << "Failed to init inference.";

  //连接网络的输入输出到变量上
  // init blobs
  instance_pt_blob_ = inference_->get_blob(network_param.instance_pt_blob());
  CHECK_NOTNULL(instance_pt_blob_.get());
  category_pt_blob_ = inference_->get_blob(network_param.category_pt_blob());
  CHECK_NOTNULL(category_pt_blob_.get());
  confidence_pt_blob_ = inference_->get_blob(network_param.confidence_pt_blob());
  CHECK_NOTNULL(confidence_pt_blob_.get());
  height_pt_blob_ = inference_->get_blob(network_param.height_pt_blob());
  CHECK_NOTNULL(height_pt_blob_.get());
  feature_blob_ = inference_->get_blob(network_param.feature_blob());
  CHECK_NOTNULL(feature_blob_.get());
  if (cnnseg_param_.do_classification()) {
    classify_pt_blob_ = inference_->get_blob(network_param.class_pt_blob());
    CHECK_NOTNULL(classify_pt_blob_.get());
  }
  if (cnnseg_param_.do_heading()) {
    heading_pt_blob_ = inference_->get_blob(network_param.heading_pt_blob());
    CHECK_NOTNULL(heading_pt_blob_.get());
  }

  //初始化特征提取器
  // init feature generator
  feature_generator_.reset(new FeatureGenerator);
  ACHECK(feature_generator_->Init(feature_param, feature_blob_.get())) << "Failed to init feature generator.";

  point2grid_.reserve(kDefaultPointCloudSize);

  // InitClusterAndBackgroundSegmentation()：初始化SPP集群，并对点云进行背景分割，根据已知地面信息去掉表示地面的点云
  // init cluster and background segmentation methods
  ACHECK(InitClusterAndBackgroundSegmentation());

  // NCut算法补充
  // secondary segmentor
  if (cnnseg_param_.fill_recall_with_ncut()) {
     secondary_segmentor.reset(new NCutSegmentation());
     if(!secondary_segmentor->Init(SegmentationInitOptions())) {
         AERROR<<"initialized secondary segmentor fails";
         return false;
     }
  }
  return true;
}
```

**Segment()**：执行CNNSeg算法

```cpp
bool CNNSegmentation::Segment(const SegmentationOptions& options, LidarFrame* frame) {
  // check input
  if (frame == nullptr) {
    AERROR << "Input null frame ptr.";
    return false;
  }
  if (frame->cloud == nullptr) {
    AERROR << "Input null frame cloud.";
    return false;
  }
  if (frame->world_cloud == nullptr) {
    AERROR << "Input null frame world cloud.";
    return false;
  }
  if (frame->cloud->size() == 0) {
    AERROR << "Input none points.";
    return false;
  }
  if (frame->cloud->size() != frame->world_cloud->size()) {
    AERROR << "Cloud size and world cloud size not consistent.";
    return false;
  }
  // record input cloud and lidar frame
  original_cloud_ = frame->cloud;
  original_world_cloud_ = frame->world_cloud;
  lidar_frame_ref_ = frame;

  // check output
  frame->segmented_objects.clear();
  worker_.WakeUp();

  // note we should use origninal cloud here, frame->cloud may be exchanged
  Timer timer;

  //MapPointToGrid():
  //映射3D点云到2D的索引图上，这样可以利用图像CNN分割的方法来对点云进行分割
  //不能直接对3D点云进行训练推断，那样的话参数太多，且单独的一个点云并不具备实际意义
  // map 3d points to 2d image grids
  MapPointToGrid(original_cloud_);
  mapping_time_ = timer.toc(true);

  if (cudaSetDevice(gpu_id_) != cudaSuccess) {
    AERROR << "Failed to set device to " << gpu_id_;
    return false;
  }

  //特征提取器提取点云特征信息
  //对映射后的点云进行特征提取
  // generate features
  feature_generator_->Generate(original_cloud_, point2grid_);
  feature_time_ = timer.toc(true);

  // CNN模型推测
  // model inference
  inference_->Infer();
  infer_time_ = timer.toc(true);

  //GetObjectsFromSppEngine():处理CNN模型推测的集群信息
  //从SPP引擎中获取侦测到的对象
  // processing clustering
  GetObjectsFromSppEngine(&frame->segmented_objects);

  ncut_time_ = timer.toc(true);

  AINFO << "CNNSEG: mapping: " << mapping_time_ << "\t"
        << " feature: " << feature_time_ << "\t"
        << " infer: " << infer_time_ << "\t"
        << " fg-seg: " << fg_seg_time_ << "\t"
        << " join: " << join_time_ << "\t"
        << " collect: " << collect_time_ << "\t"
        << " ncut: " << ncut_time_;
  return true;
}
```

**GetObjectsFromSppEngine()**:处理CNN模型推测的集群信息

```cpp
void CNNSegmentation::GetObjectsFromSppEngine(std::vector<std::shared_ptr<Object>>* objects) {
  Timer timer;
  spp_engine_.GetSppData().grid_indices = point2grid_.data();
    
  //处理前景分割对象
  size_t num_foreground = spp_engine_.ProcessForegroundSegmentation(original_cloud_);
  fg_seg_time_ = timer.toc(true);
  // should sync with worker before do background segmentation
  worker_.Join();
  join_time_ = timer.toc(true);
  // copy height from roi cloud to origin cloud,
  // note ground points include other noise points
  // filtered by ground detection post process
  // AINFO << "Use origin cloud and copy height";
  for (std::size_t i = 0; i < lidar_frame_ref_->roi_indices.indices.size(); ++i) {
    const int roi_id = lidar_frame_ref_->roi_indices.indices[i];
    original_cloud_->mutable_points_height()->at(roi_id) = roi_cloud_->points_height(i);
    if (roi_cloud_->mutable_points_label()->at(i) == static_cast<uint8_t>(LidarPointLabel::GROUND)) {
      original_cloud_->mutable_points_label()->at(roi_id) = roi_cloud_->points_label().at(i);
    }
  }
  memcpy(&original_world_cloud_->mutable_points_height()->at(0), &original_cloud_->points_height().at(0),
         sizeof(float) * original_cloud_->size());
  memcpy(&original_world_cloud_->mutable_points_label()->at(0), &original_cloud_->points_label().at(0),
         sizeof(uint8_t) * original_cloud_->size());
  if (cnnseg_param_.remove_ground_points()) {
    num_foreground = spp_engine_.RemoveGroundPointsInForegroundCluster(original_cloud_, lidar_frame_ref_->roi_indices,
                                                                       lidar_frame_ref_->non_ground_indices);
    if (num_foreground == 0) {
      ADEBUG << "No foreground segmentation output";
    }
  }

  const auto& clusters = spp_engine_.clusters();
  objects->clear();
  base::ObjectPool::Instance().BatchGet(clusters.size(), objects);
  size_t valid = 0;

  // prepare for valid point cloud for seconary segmentor
  // after removing pts from primary segmentor, ground and non roi pts
  CloudMask mask;
  if (cnnseg_param_.fill_recall_with_ncut()) {
     mask.Set(original_cloud_->size(), 0);
     if (cnnseg_param_.ncut_with_roi())
        mask.AddIndicesOfIndices(lidar_frame_ref_->roi_indices,
      lidar_frame_ref_->non_ground_indices, 1);
     else
      mask.AddIndices(lidar_frame_ref_->non_ground_indices, 1);
  }

  if (cnnseg_param_.fill_recall_with_ncut()) {
    mask.FilterOutlierCloud(original_cloud_);
  }

//循环所有集群，过滤掉点云数少的集群，生成对象列表。
  for (int i = 0; i < static_cast<int>(clusters.size()); ++i) {
    if (clusters[i]->points.size() <= cnnseg_param_.min_pts_num() && clusters[i]->pixels.size() < cnnseg_param_.min_pts_num()) {
      continue;
    }
    auto& cluster = clusters[i];
    auto& object = objects->at(valid);
    object->lidar_supplement.num_points_in_roi = cluster->points_in_roi;
    object->lidar_supplement.on_use = true;
    object->lidar_supplement.is_background = false;

//复制点云信息到侦测到的对象上
    object->lidar_supplement.cloud.CopyPointCloud(*original_cloud_, cluster->point_ids);
    object->lidar_supplement.cloud_world.CopyPointCloud(*original_world_cloud_, cluster->point_ids);
    object->lidar_supplement.lidar_algorithm_type = base::LidarAlgorithmType::CNNSeg;

    // for miss detection, try to fill recall with ncut
    if (cnnseg_param_.fill_recall_with_ncut()) {
        mask.RemoveIndices(cluster->point_ids);
    }

    object->confidence = cluster->confidence;
    object->id = static_cast<int>(valid);

//计算所属每个分类的概率
    if (cnnseg_param_.do_classification()) {
      object->lidar_supplement.raw_probs.push_back(std::vector<float>(static_cast<int>(base::ObjectType::MAX_OBJECT_TYPE), 0.f));
      object->lidar_supplement.raw_classification_methods.push_back(Name());
      object->lidar_supplement.raw_probs.back()[static_cast<int>(base::ObjectType::UNKNOWN)] =
          cluster->class_prob[static_cast<int>(MetaType::META_UNKNOWN)];
      object->lidar_supplement.raw_probs.back()[static_cast<int>(base::ObjectType::PEDESTRIAN)] =
          cluster->class_prob[static_cast<int>(MetaType::META_PEDESTRIAN)];
      object->lidar_supplement.raw_probs.back()[static_cast<int>(base::ObjectType::BICYCLE)] =
          cluster->class_prob[static_cast<int>(MetaType::META_NONMOT)];
      object->lidar_supplement.raw_probs.back()[static_cast<int>(base::ObjectType::VEHICLE)] =
          cluster->class_prob[static_cast<int>(MetaType::META_SMALLMOT)] + cluster->class_prob[static_cast<int>(MetaType::META_BIGMOT)];
      // copy to type
      object->type_probs.assign(object->lidar_supplement.raw_probs.back().begin(), object->lidar_supplement.raw_probs.back().end());
      object->type = static_cast<base::ObjectType>(
          std::distance(object->type_probs.begin(), std::max_element(object->type_probs.begin(), object->type_probs.end())));
    }

//计算方向
    if (cnnseg_param_.do_heading()) {
      // object->theta = cluster->yaw;
      // object->direction[0] = cos(cluster->yaw);
      // object->direction[1] = sin(cluster->yaw);
      // 2018.6.21, switch to axis rotated projection
      // should be reverted after retrain model.
      static const float quater_pi = static_cast<float>(M_PI) * 0.25f;
      object->theta = cluster->yaw - quater_pi;
      object->direction[0] = cosf(cluster->yaw - quater_pi);
      object->direction[1] = sinf(cluster->yaw - quater_pi);
      object->direction[2] = 0;
      object->lidar_supplement.is_orientation_ready = true;
    }
    ++valid;
  }
  objects->resize(valid);
  int first_size = objects->size();

  // add additional object seg logic with ncut if cnnseg miss detects
  if (cnnseg_param_.fill_recall_with_ncut() && secondary_segmentor) {
      mask.GetValidIndices(&(lidar_frame_ref_->secondary_indices));
      secondary_segmentor->Segment(SegmentationOptions(), lidar_frame_ref_);
  //segment based on lidar frame ref
  }
  #if CNN_VISUALIZATION
    publishPointCloud(pub_ground_cut_cloud_, lidar_frame_ref_->cloud, lidar_frame_ref_->non_ground_indices);
  #endif
 
  collect_time_ = timer.toc(true);
}
```

## 6.基于PointPillars算法的激光雷达感知

### 6.1 launch文件结构

```
    <module>
        <name>perception</name>
        <dag_conf>/zhito/modules/perception/launcher_perception/dag/dag_lidar_detection.dag</dag_conf>
        <process_name>lidar_perception</process_name>
        <version>1.0.0</version>
    </module> 
```

### 6.2 dag文件结构

### 6.3 配置文件结构


### 6.4 Component实现

1.Detection_component

/modules/perception/onboard/component/detection_component.cc

#### **DetectionComponent::Init():**

读取配置文件，做一些变量初始化命名，创建writer结点，再初始化算法插件:

```cpp
bool DetectionComponent::Init() {
  //读取配置文件
  //地址：modules/perception/launcher_perception/conf/lidar/velodyne32_detection_conf.pb.txt
  LidarDetectionComponentConfig comp_config;
  if (!GetProtoConfig(&comp_config)) {
    return false;
  }
  ADEBUG << "Lidar Component Configs: " << comp_config.DebugString();
  output_channel_name_ = comp_config.output_channel_name();
  sensor_name_ = comp_config.sensor_name();
  lidar2novatel_tf2_child_frame_id_ = comp_config.lidar2novatel_tf2_child_frame_id();
  lidar_query_tf_offset_ = static_cast<float>(comp_config.lidar_query_tf_offset());
  enable_hdmap_ = comp_config.enable_hdmap();
  writer_ = node_->CreateWriter<LidarFrameMessage>(output_channel_name_);
#ifdef PUB_LIDAR_DETECTION
  pub_writer_ = node_->CreateWriter<PerceptionObstacles>("/zhito/perception/detection");
#endif
  //初始化成员算法类
  if (!InitAlgorithmPlugin()) {
    AERROR << "Failed to init detection component algorithm plugin.";
    return false;
  }
  return true;
}
```

**InitAlgorithPlugin():**在调用各模块类的处理逻辑process，先对个模块功能类进行参数初始化，先调用`LidarObstacleDetection::Init`，后分别分别调用各模块功能类（预处理，根据高精度hdmap获取离定位点一定范围的道路、交叉路口信息，pointpillar目标检测）的`init`方法

```cpp
      bool DetectionComponent::InitAlgorithmPlugin()
      {
        /*读取传感器元数据，元数据的读取是通过SensorManager来完成,SensorManager 类经宏定义 DECLARE_SINGLETON(SensorManager) 修饰成为单例类，           *单例对象调用GetSensorInfo函数获取传感器名sensor_name_对应的传感器信息SensorInfo
          *其在初始化时会读取modules/perception/production/data/perception/common/sensor_meta.pt的包含所有传感器元数据的列表*/
        ACHECK(common::SensorManager::Instance()->GetSensorInfo(sensor_name_,&sensor_info_));
        // zhito/modules/perception/lib/registerer/registerer.h
        // 父类指针detector指向子类LidarObstacleDetection的对象
        lidar::BaseLidarObstacleDetection *detector = lidar::BaseLidarObstacleDetectionRegisterer::GetInstanceByName(detector_name_);     // 调用宏定义类的静态方法
        CHECK_NOTNULL(detector);
        detector_.reset(detector);
        // lidar型号，hdmap是否使用
        lidar::LidarObstacleDetectionInitOptions init_options;
        init_options.sensor_name = sensor_name_;
        // 调用DEFINE_bool宏获取hdmap选择FLAGS_obs_enable_hdmap_input
        // DEFINE_bool宏位于：modules/perception/onboard/common_flags/common_flags.cpp
        init_options.enable_hdmap_input = FLAGS_obs_enable_hdmap_input && enable_hdmap_;
        // 多态性：子类LidarObstacleDetection重写父类BaseLidarObstacleDetection的虚函数init
        // 调用子类LidarObstacleDetection的init函数
        ACHECK(detector_->Init(init_options)) << "lidar obstacle detection init error";
        lidar2world_trans_.Init(lidar2novatel_tf2_child_frame_id_);
        return true;
      }   
```

1)获取传感器信息sensor_info_，对应代码：

```cpp
lidar::BaseLidarObstacleDetection *detector = lidar::BaseLidarObstacleDetectionRegisterer::GetInstanceByName(detector_name_);     // 调用宏定义类的静态方法
 CHECK_NOTNULL(detector);
detector_.reset(detector);

```

SensorManager类路径：zhito/modules/perception/common/sensor_manager/sensor_manager.cc

common::SensorManager::Instance()会返回SensorManager的唯一实例，同时调用构造函数，而构造函数又调用Init()方法,对传感器元数据初始化,读取modules/perception/production/data/perception/common/sensor_meta.pt的包含所有传感器元数据，并将传感器名字和传感器信息SensorInfo存储在sensor_info_map_字典;

```cpp
      // glog 提供了CHECK()宏帮助我们检查程序的错误，当CHECK()的条件不满足时，它会记录FATAL日志并终止程序
      SensorManager::SensorManager() { CHECK_EQ(this->Init(), true); }

      bool SensorManager::Init()
      {
        std::lock_guard<std::mutex> lock(mutex_);
        if (inited_)
        {
          return true;
        }

        sensor_info_map_.clear();
        distort_model_map_.clear();
        undistort_model_map_.clear();
        // 传感器元数据(名字，传感器型号，摆放位置)文件路径： zhito/modules/perception/production/data/perception/common/sensor_meta.pt
        // 调用gflags库DEFINE_type宏获取传感器元数据文件路径FLAGS_obs_sensor_meta_path
        const std::string file_path = cyber::common::GetAbsolutePath(lib::ConfigManager::Instance()->work_root(), FLAGS_obs_sensor_meta_path);

        MultiSensorMeta sensor_list_proto;
        // 从文件中读取信息存储到sensor_list_proto中
        if (!GetProtoFromASCIIFile(file_path, &sensor_list_proto))
        {
          AERROR << "Invalid MultiSensorMeta file: " << FLAGS_obs_sensor_meta_path;
          return false;
        }

        auto AddSensorInfo = [this](const SensorMeta &sensor_meta_proto)
        {
          SensorInfo sensor_info;
          sensor_info.name = sensor_meta_proto.name();
          sensor_info.type = static_cast<SensorType>(sensor_meta_proto.type());
          sensor_info.orientation =
              static_cast<SensorOrientation>(sensor_meta_proto.orientation());
          sensor_info.frame_id = sensor_meta_proto.name();
          // sensor_info_map_字典存储传感器名字和传感器信息SensorInfo
          // SensorInfo 结构体类型 位于zhito/modules/perception/base/sensor_meta.h
          auto pair = sensor_info_map_.insert(
              make_pair(sensor_meta_proto.name(), sensor_info));
          if (!pair.second)
          {
            AERROR << "Duplicate sensor name error.";
            return false;
          }
            
        for (const SensorMeta &sensor_meta_proto : sensor_list_proto.sensor_meta())
        {
          if (!AddSensorInfo(sensor_meta_proto))
          {
            AERROR << "Failed to add sensor_info: " << sensor_meta_proto.name();
            return false;
          }
        }

        inited_ = true;
        AINFO << "Init sensor_manager success.";
        return true;
      }

      // 根据传感器名获取传感器信息SensorInfo
      bool SensorManager::GetSensorInfo(const std::string &name,
                                        SensorInfo *sensor_info) const
      {
        if (sensor_info == nullptr)
        {
          AERROR << "Nullptr error.";
          return false;
        }

        const auto &itr = sensor_info_map_.find(name);
        if (itr == sensor_info_map_.end())
        {
          return false;
        }

        *sensor_info = itr->second;
        return true;
      }
```

zhito/modules\message\perception\proto\sensor_meta_schema.proto

传感器信息proto字段

```cpp
message SensorMeta {
  enum SensorType {
    UNKNOWN_SENSOR_TYPE = -1;
    VELODYNE_64 = 0;
    VELODYNE_32 = 1;
    VELODYNE_16 = 2;
    LDLIDAR_4 = 3;
    LDLIDAR_1 = 4;
    SHORT_RANGE_RADAR = 5;
    LONG_RANGE_RADAR = 6;
    MONOCULAR_CAMERA = 7;
    STEREO_CAMERA = 8;
    ULTRASONIC = 9;
    VELODYNE_128 = 10;
  }

  enum SensorOrientation {
    FRONT = 0;
    LEFT_FORWARD = 1;
    LEFT = 2;
    LEFT_BACKWARD = 3;
    REAR = 4;
    RIGHT_BACKWARD = 5;
    RIGHT = 6;
    RIGHT_FORWARD = 7;
    PANORAMIC = 8;
  }

  optional string name = 1;
  optional SensorType type = 2;
  optional SensorOrientation orientation = 3;
}


message MultiSensorMeta {
  repeated SensorMeta sensor_meta = 1;
}
```

SensorInfo类型，位于zhito\modules\common\perception_util\basesensor_meta.h

```cpp
struct SensorInfo {
  std::string name = "UNKNONW_SENSOR";
  SensorType type = SensorType::UNKNOWN_SENSOR_TYPE;
  SensorOrientation orientation = SensorOrientation::FRONT;
  std::string frame_id = "UNKNOWN_FRAME_ID";
  void Reset() {
    name = "UNKNONW_SENSOR";
    type = SensorType::UNKNOWN_SENSOR_TYPE;
    orientation = SensorOrientation::FRONT;
    frame_id = "UNKNOWN_FRAME_ID";
  }
};
```

2）lidar障碍物检测基类对象指针指向子类的对象，对应代码：

```cpp
lidar::BaseLidarObstacleDetection *detector = lidar::BaseLidarObstacleDetectionRegisterer::GetInstanceByName(detector_name_);     // 调用宏定义类的静态方法

```

BaseLidarObstacleDetectionRegistere作为雷达障碍物检测的基类，通过多态形式调用子类的init函数，路径：

zhito/modules/perception/lidar/lib/interface/base_lidar_obstacle_detection.h

lidar::BaseLidarObstacleDetectionRegisterer调用一个宏定义类，类BaseLidarObstacleDetectionRegisterer路径：

zhito/modules/perception/lib/registerer/registerer.h

```c++
#define PERCEPTION_REGISTER_REGISTERER(base_class)                    \
  class base_class##Registerer {                                      \
    typedef ::apollo::perception::lib::Any Any;                       \
    typedef ::apollo::perception::lib::FactoryMap FactoryMap;         \
                                                                      \
   public:                                                            \
    static base_class *GetInstanceByName(const ::std::string &name) { \
      FactoryMap &map =                                               \
          ::apollo::perception::lib::GlobalFactoryMap()[#base_class]; \
      FactoryMap::iterator iter = map.find(name);                     \
      if (iter == map.end()) {                                        \
        for (auto c : map) {                                          \
          AERROR << "Instance:" << c.first;                           \
        }                                                             \
        AERROR << "Get instance " << name << " failed.";              \
        return nullptr;                                               \
      }                                                               \
      Any object = iter->second->NewInstance();                       \
      return *(object.AnyCast<base_class *>());                       \
    }                                                                 \
    static std::vector<base_class *> GetAllInstances() {              \
      std::vector<base_class *> instances;                            \
      FactoryMap &map =                                               \
          ::apollo::perception::lib::GlobalFactoryMap()[#base_class]; \
      instances.reserve(map.size());                                  \
      for (auto item : map) {                                         \
        Any object = item.second->NewInstance();                      \
        instances.push_back(*(object.AnyCast<base_class *>()));       \
      }                                                               \
      return instances;                                               \
    }                                                                 \
    static const ::std::string GetUniqInstanceName() {                \
      FactoryMap &map =                                               \
          ::apollo::perception::lib::GlobalFactoryMap()[#base_class]; \
      CHECK_EQ(map.size(), 1U) << map.size();                         \
      return map.begin()->first;                                      \
    }                                                                 \
    static base_class *GetUniqInstance() {                            \
      FactoryMap &map =                                               \
          ::apollo::perception::lib::GlobalFactoryMap()[#base_class]; \
      CHECK_EQ(map.size(), 1U) << map.size();                         \
      Any object = map.begin()->second->NewInstance();                \
      return *(object.AnyCast<base_class *>());                       \
    }                                                                 \
    static bool IsValid(const ::std::string &name) {                  \
      FactoryMap &map =                                               \
          ::apollo::perception::lib::GlobalFactoryMap()[#base_class]; \
      return map.find(name) != map.end();                             \
    }                                                                 \
  };

```

3)初始化雷达型号，是否使用hdmap，作为类LidarObstacleDetection的init函数传入参数

```cpp
        lidar::LidarObstacleDetectionInitOptions init_options;
        init_options.sensor_name = sensor_name_;
        // 调用DEFINE_bool宏返回FLAGS_obs_enable_hdmap_input,bool类型,表达是否有hdmap输入
        // DEFINE_bool宏位于：modules/perception/onboard/common_flags/common_flags.cpp
        init_options.enable_hdmap_input = FLAGS_obs_enable_hdmap_input && enable_hdmap_;
```

类LidarObstacleDetectionInitOptions位于

zhito/modules/perception/lidar/lib/interface/base_lidar_obstacle_detection.h

```cpp
struct LidarObstacleDetectionInitOptions {
  std::string sensor_name = "velodyne64";
  bool enable_hdmap_input = true;
};
```

4）调用子类LidarObstacleDetection的init函数初始化参数

```cpp
        // 多态性：子类LidarObstacleDetection重写父类BaseLidarObstacleDetection的虚函数init
        // 调用子类LidarObstacleDetection的init函数
        ACHECK(detector_->Init(init_options)) << "lidar obstacle detection init error";

```

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



Init函数位于：zhito/modules/perception/lidar/app/lidar_obstacle_detection.cc

障碍物检测类的初始化函数Init，初始化各模块的参数

```cpp
      bool LidarObstacleDetection::Init(const LidarObstacleDetectionInitOptions &options)
      {
        auto &sensor_name = options.sensor_name; // 传感器名，如"velodyne128"
        // ConfigManager类经宏定义 DECLARE_SINGLETON(ConfigManager) 修饰成为单例类
        auto config_manager = lib::ConfigManager::Instance();
        const lib::ModelConfig *model_config = nullptr;
        // 获取 LidarObstacleDetection 配置参数model_config,第一次调用GetModelConfig将各模块功能类和其配置参数存储在字典，
        // 从字典查找LidarObstacleDetection对应的参数信息
        // LidarObstacleDetection在文件中是存储在 
        // zhito/modules/perception/production/conf/perception/lidar/modules/lidar_obstacle_pipeline.config
        ACHECK(config_manager->GetModelConfig(Name(), &model_config));

        const std::string work_root = config_manager->work_root();
        std::string config_file;
        std::string root_path;
        // root_path:./data/perception/lidar/models/lidar_obstacle_pipeline
        ACHECK(model_config->get_value("root_path", &root_path));
        // zhito/modules/perception/production/lidar/models/lidar_obstacle_pipeline
        config_file = cyber::common::GetAbsolutePath(work_root, root_path);
        // zhito/modules/perception/production/data/perception/lidar/models/lidar_obstacle_pipeline/velodyne128
        config_file = cyber::common::GetAbsolutePath(config_file, sensor_name);
        // zhito/modules/perception/launcher_perception/data/perception/lidar/
        // models/lidar_obstacle_pipeline/velodyne32/lidar_obstacle_detection.conf
        config_file = cyber::common::GetAbsolutePath(config_file, "lidar_obstacle_detection.conf");
        /*
        message LidarObstacleDetectionConfig {
        optional string preprocessor = 1 [default = "PointCloudPreprocessor"];
        optional string detector = 2 [default = "PointPillarsDetection"];
        optional bool use_map_manager = 3 [default = true];
        optional bool use_object_filter_bank = 4 [default = true];
        }
        */
        LidarObstacleDetectionConfig config;
        // 把lidar_obstacle_detection.conf写入proto LidarObstacleDetectionConfig信息中
        ACHECK(cyber::common::GetProtoFromFile(config_file, &config));
        use_map_manager_ = config.use_map_manager();               // true
        use_object_filter_bank_ = config.use_object_filter_bank(); // true
        // PointPillarsDetection
        use_object_builder_ = ("PointPillarsDetection" != config.detector());

        use_map_manager_ = use_map_manager_ && options.enable_hdmap_input; // true

        SceneManagerInitOptions scene_manager_init_options;
        ACHECK(SceneManager::Instance().Init(scene_manager_init_options));
        // 是否使用高精度地图
        if (use_map_manager_)
        {
          MapManagerInitOptions map_manager_init_options;
          // hdmap初始化
          if (!map_manager_.Init(map_manager_init_options))
          {
            AINFO << "Failed to init map manager.";
            use_map_manager_ = false;
          }
        }
        // 激光点云预处理：初始化基类对象，让其指针指向子类
        BasePointCloudPreprocessor *preprocessor = BasePointCloudPreprocessorRegisterer::GetInstanceByName(config.preprocessor());
        CHECK_NOTNULL(preprocessor);
        cloud_preprocessor_.reset(preprocessor);

        // 激光雷达的型号
        PointCloudPreprocessorInitOptions preprocessor_init_options;
        preprocessor_init_options.sensor_name = sensor_name;
        // 点云预处理初始化
        ACHECK(cloud_preprocessor_->Init(preprocessor_init_options)) << "lidar preprocessor init error";
        // 激光障碍物检测
        BaseLidarDetector *detector = BaseLidarDetectorRegisterer::GetInstanceByName(config.detector());
        BaseLidarDetectorRegisterer::GetInstanceByName(config.detector());
        detector_.reset(detector);
        LidarDetectorInitOptions detection_init_options;
        detection_init_options.sensor_name = sensor_name;
        // 激光雷达障碍物检测初始化
        ACHECK(detector_->Init(detection_init_options)) << "lidar detector init error";

        if (use_object_builder_)
        {
          // ObjectBuilder：构建障碍物目标包围框类信息
          ObjectBuilderInitOptions builder_init_options;
          ACHECK(builder_.Init(builder_init_options));
        }

        if (use_object_filter_bank_)
        {
          ObjectFilterInitOptions filter_bank_init_options;
          filter_bank_init_options.sensor_name = sensor_name;
          // ObjectFilterBank： 调用ObjectFilterBank：对目标进行ROIBoundaryFilter
          ACHECK(filter_bank_.Init(filter_bank_init_options));
        }

        return true;
      }

```

1)先定义单例类ConfigManager对象，调用GetModelConfig获取障碍物检测类的配置参数

根据 LidarObstacleDetection类名获取其配置参数，第一次调用GetModelConfig()，它将进一步调用init函数将各模块功能类和其配置参数存储在字典中，从字典查找LidarObstacleDetection对应的参数信息，存储在存储在ModelConfig类对象中，然后利用ModelConfig类的get_value函数，即可对应查询到具体的配置参数数值
**GetModelConfig():**

```cpp
// 根据类名获取模型配置参数
bool ConfigManager::GetModelConfig(const std::string &model_name,const ModelConfig **model_config) {
  if (!inited_ && !Init()) {
    return false;
  }

  auto citer = model_config_map_.find(model_name);
  if (citer == model_config_map_.end()) {
    return false;
  }
  *model_config = citer->second;
  return true;
}

bool ConfigManager::Init() {
  MutexLock lock(&mutex_);
  return InitInternal();
}

bool ConfigManager::InitInternal() {
  if (inited_) {
    return true;
  }
  // 释放内存
  for (auto iter = model_config_map_.begin(); iter != model_config_map_.end();
       ++iter) {
    delete iter->second;
  }
  model_config_map_.clear();
  // 调用gflags库DEFINE_type宏获取传感器的参数文件路径FLAGS_config_manager_path
  // FLAGS_config_manager_path = "./conf"
  // apollo/modules/perception/production/conf/
  std::string config_module_path = GetAbsolutePath(work_root_, FLAGS_config_manager_path);
  AINFO << "WORK_ROOT: " << work_root_ << " config_root_path: " << config_module_path;

  std::vector<std::string> model_config_files;
  // 递归遍历conf文件夹下所有文件名，返回后缀包含config_manager的所有文件路径model_config_files
  if (!common::GetFileList(config_module_path, "config_manager.config",
                           &model_config_files)) {
    AERROR << "config_root_path : " << config_module_path << " get file list error.";
    return false;
  }

  for (const auto &model_config_file : model_config_files) {
    // 用定义的proto message ModelConfigFileListProto 读取文件 config_manager.config 的model_config_path参数
    ModelConfigFileListProto file_list_proto;
    if (!GetProtoFromASCIIFile(model_config_file, &file_list_proto)) {
      AERROR << "Invalid ModelConfigFileListProto file: " << model_config_file;
      return false;
    }
    // model_config_path : 每一个后缀名为"config_manager.config"的文件
    for (const std::string &model_config_path : file_list_proto.model_config_path()) {
      // 获取绝对路径
      const std::string abs_path = GetAbsolutePath(work_root_, model_config_path);
      // 用定义的proto message MultiModelConfigProto 读取文件 参数信息，存储moudle下所有文件名
      MultiModelConfigProto multi_model_config_proto;
      if (!GetProtoFromASCIIFile(abs_path, &multi_model_config_proto)) {
        AERROR << "Invalid MultiModelConfigProto file: " << abs_path;
        return false;
      }
      // model_config_proto 每一个模块下各功能的配置参数
      for (const ModelConfigProto &model_config_proto : multi_model_config_proto.model_configs()) {
        // // 用定义的proto message ModelConfig 读取moudle下所有文件的参数信息 
        ModelConfig *model_config = new ModelConfig();
        if (!model_config->Reset(model_config_proto)) {
          return false;
        }

        AINFO << "load ModelConfig succ. name: " << model_config->name();
        // 将各模块功能类名和配置参数存储在字典 model_config_map_ 中
        auto result = model_config_map_.emplace(model_config->name(), model_config);
        if (!result.second) {
          AWARN << "duplicate ModelConfig, name: " << model_config->name();
          return false;
        }
      }
    }
  }   
```

用Proto读取文件参数，最终会将各模块功能类名和配置参数存储在字典 model_config_map_ ，定义proto message信息位于：\modules\message\perception\proto文件中，如下：

```yaml
syntax = "proto2";
package apollo.perception;

message KeyValueInt {
  optional string name = 1;
  optional int32 value = 2;
}

message KeyValueString {
  optional string name = 1;
  optional bytes value = 2;
}

message KeyValueDouble {
  optional string name = 1;
  optional double value = 2;
}

message KeyValueFloat {
  optional string name = 1;
  optional float value = 2;
}

message KeyValueBool {
  optional string name = 1;
  optional bool value = 2;
}

message KeyValueArrayInt {
  optional string name = 1;
  repeated int32 values = 2;
}

message KeyValueArrayString {
  optional string name = 1;
  repeated bytes values = 2;
}

message KeyValueArrayDouble {
  optional string name = 1;
  repeated double values = 2;
}

message KeyValueArrayFloat {
  optional string name = 1;
  repeated float values = 2;
}

message KeyValueArrayBool {
  optional string name = 1;
  repeated bool values = 2;
}
message ModelConfigProto {
  optional string name = 1;
  optional string version = 2;

  repeated KeyValueInt integer_params = 3;
  repeated KeyValueString string_params = 4;
  repeated KeyValueDouble double_params = 5;
  repeated KeyValueFloat float_params = 6;
  repeated KeyValueBool bool_params = 7;
  repeated KeyValueArrayInt array_integer_params = 8;
  repeated KeyValueArrayString array_string_params = 9;
  repeated KeyValueArrayDouble array_double_params = 10;
  repeated KeyValueArrayFloat array_float_params = 11;
  repeated KeyValueArrayBool array_bool_params = 12;
}

message MultiModelConfigProto {
  repeated ModelConfigProto model_configs = 1;
}

message ModelConfigFileListProto {
 repeated string model_config_path = 1;
}
```

每一个message相当于定义了一个struct，其中包含许多成员变量。其中ModelConfigFileListProto定义了一个向量，用来指定每个具体参数配置文件的位置，而MultiModelConfigProto则定义了一个ModelConfigProto类型的向量，即定义的具体配置参数，从ModelConfigProto类型的message文件可见配置参数为string类型到不同数据类型的一个map映射。

关于lidar模块，首先由zhito/modules/perception/production/conf/perception/lidar/config_manager.config文件实例化上述protobuf文件中定义的message ModelConfigFileListProto：

```yaml
model_config_path: "./conf/perception/lidar/modules/map_manager.config"
model_config_path: "./conf/perception/lidar/modules/scene_manager.config"
model_config_path: "./conf/perception/lidar/modules/object_filter_bank.config"
model_config_path: "./conf/perception/lidar/modules/pointcloud_preprocessor.config"
model_config_path: "./conf/perception/lidar/modules/roi_boundary_filter.config"
model_config_path: "./conf/perception/lidar/modules/hdmap_roi_filter.config"
model_config_path: "./conf/perception/lidar/modules/cnnseg.config"
model_config_path: "./conf/perception/lidar/modules/ncut.config"
model_config_path: "./conf/perception/lidar/modules/spatio_temporal_ground_detector.config"
model_config_path: "./conf/perception/lidar/modules/lidar_obstacle_pipeline.config"
model_config_path: "./conf/perception/lidar/modules/fused_classifier.config"
model_config_path: "./conf/perception/lidar/modules/multi_lidar_fusion.config"
model_config_path: "./conf/perception/lidar/modules/roi_service.config"
model_config_path: "./conf/perception/lidar/modules/ground_service.config"
model_config_path: "./conf/perception/lidar/modules/ground_service_detector.config"
```

其对ModelConfigFileListProto消息中的model_config_path成员变量进行了实例化，指明参数定义文件的路径。以lidar_obstacle_pipeline.config为例，其
具体内容为

```yaml
model_configs {
    name: "LidarObstacleDetection"
    version: "1.0.0"
    string_params {
        name: "root_path"
        value: "./data/perception/lidar/models/lidar_obstacle_pipeline"
    }
}

model_configs {
    name: "LidarObstacleTracking"
    version: "1.0.0"
    string_params {
        name: "root_path"
        value: "./data/perception/lidar/models/lidar_obstacle_pipeline"
    }
}
```

该配置文件包含激光雷达检测和跟踪两个功能，其对`MultiModelConfigProto`消息中的`model_configs`成员变量进行初始化，`name`是功能类名

#### **DetectionComponent::Proc():**

主要通过调用Process()算法处理逻辑

```cpp
      bool DetectionComponent::Proc(const std::shared_ptr<drivers::PointCloud> &message)
      {
        AINFO << std::setprecision(16)
              << "Enter detection component, message timestamp: "
              << message->measurement_time()
              << " current timestamp: " << Clock::NowInSeconds();

        auto out_message = std::make_shared<LidarFrameMessage>();

        bool status = InternalProc(message, out_message);
        if (status)
        {
          writer_->Write(out_message);
          AINFO << "Send lidar detect output message.";
        }
        return status;
      }

```

Proc()调用`InternalProc`方法，`InternalProc`继续调用`zhito/modules/perception/lidar/app/lidar_obstacle_detection.h`中的`Process() `算法处理逻辑

**InternalProc():**

```cpp
      bool DetectionComponent::InternalProc(
          const std::shared_ptr<const drivers::PointCloud> &in_message,
          const std::shared_ptr<LidarFrameMessage> &out_message)
      /*
      输入：drivers::PointCloud 原始点云
      输出：LidarFrameMessaglidar 处理结果
      */
      { // 序列号
        uint32_t seq_num = seq_num_.fetch_add(1);
        // 时间戳
        const double timestamp = in_message->measurement_time();
        // 当前时间
        const double cur_time = Clock::NowInSeconds();
        const double start_latency = (cur_time - timestamp) * 1e3;
        AINFO << std::setprecision(16) << "FRAME_STATISTICS:Lidar:Start:msg_time["
              << timestamp << "]:sensor[" << sensor_name_ << "]:cur_time[" << cur_time
              << "]:cur_latency[" << start_latency << "]";

        out_message->timestamp_ = timestamp;
        out_message->lidar_timestamp_ = in_message->header().lidar_timestamp();
        out_message->seq_num_ = seq_num;
        // 处理状态：检测
        out_message->process_stage_ = ProcessStage::LIDAR_DETECTION;
        // 错误码
        out_message->error_code_ = apollo::common::ErrorCode::OK;

        auto &frame = out_message->lidar_frame_;
        // 并发对象池，结合单例模式，获取目标的智能指针
        // 思想：一个对象只能有一个池子,用对象从池子里面取,每个池子有一个管理者来管理所对应的池子,取对象从管理者这里申请
        frame = lidar::LidarFramePool::Instance().Get();
        frame->cloud = base::PointFCloudPool::Instance().Get();
        frame->timestamp = timestamp;
        frame->sensor_info = sensor_info_;

        Eigen::Affine3d pose = Eigen::Affine3d::Identity();
        Eigen::Affine3d pose_novatel = Eigen::Affine3d::Identity();
        const double lidar_query_tf_timestamp = timestamp - lidar_query_tf_offset_ * 0.001;
        // 获取当前帧 坐标系到世界坐标系的位置变换，GPS到世界坐标系的位置变换
        // transform_wrapper原理和ROS tf变换一致，首先各传感器的位置关系需要通过广播形式发送出去
        if (!lidar2world_trans_.GetSensor2worldTrans(lidar_query_tf_timestamp, &pose, &pose_novatel))
        {
          out_message->error_code_ = apollo::common::ErrorCode::PERCEPTION_ERROR_TF;
          AERROR << "Failed to get pose at time: " << lidar_query_tf_timestamp;
          return false;
        }
        frame->lidar2world_pose = pose;
        frame->novatel2world_pose = pose_novatel;

        // 传感器名和lidar传感器转GPS的外参转换矩阵
        lidar::LidarObstacleDetectionOptions detect_opts;
        detect_opts.sensor_name = sensor_name_;
        // lidar到世界坐标系的变换 *lidar2world_trans_  =  *detect_opts.sensor2novatel_extrinsics
        lidar2world_trans_.GetExtrinsics(&detect_opts.sensor2novatel_extrinsics);
        // 掉用LidarObstacleDetection类的Process方法
        // frame.get() 获取存储的指针
        lidar::LidarProcessResult ret = detector_->Process(detect_opts, in_message, frame.get());
        if (ret.error_code != lidar::LidarErrorCode::Succeed)
        {
          out_message->error_code_ =
              apollo::common::ErrorCode::PERCEPTION_ERROR_PROCESS;
          AERROR << "Lidar detection process error, " << ret.log;
          return false;
        }

        return true;
      }
```

**<u>Remark: 基础数据结构</u>**

R1：类(class)LidarFrameMessage：

```cpp
class LidarFrameMessage {
 public:
  LidarFrameMessage() : lidar_frame_(nullptr) {
    type_name_ = "LidarFrameMessage";
  }

  ~LidarFrameMessage() = default;

  std::string GetTypeName() const { return type_name_; }

  LidarFrameMessage* New() const { return new LidarFrameMessage; }

 public:
  double timestamp_ = 0.0;
  uint64_t lidar_timestamp_ = 0;
  uint32_t seq_num_ = 0;
  std::string type_name_;
  ProcessStage process_stage_ = ProcessStage::UNKNOWN_STAGE;
  apollo::common::ErrorCode error_code_ = apollo::common::ErrorCode::OK;
  std::shared_ptr<lidar::LidarFrame> lidar_frame_;
};
```

R2: 结构体(struct)LidarFrame:

```cpp
struct LidarFrame {
  EIGEN_MAKE_ALIGNED_OPERATOR_NEW

  // point cloud
  std::shared_ptr<base::AttributePointCloud<base::PointF>> cloud;
  // world point cloud
  std::shared_ptr<base::AttributePointCloud<base::PointD>> world_cloud;
  // timestamp
  double timestamp = 0.0;
  // lidar to world pose
  Eigen::Affine3d lidar2world_pose = Eigen::Affine3d::Identity();
  // lidar to world pose
  Eigen::Affine3d novatel2world_pose = Eigen::Affine3d::Identity();
  // hdmap struct
  std::shared_ptr<base::HdmapStruct> hdmap_struct = nullptr;
  // segmented objects
  std::vector<std::shared_ptr<base::Object>> segmented_objects;
  // tracked objects
  std::vector<std::shared_ptr<base::Object>> tracked_objects;
  // point cloud roi indices
  base::PointIndices roi_indices;
  // point cloud non ground indices
  base::PointIndices non_ground_indices;
  // secondary segmentor indices
  base::PointIndices secondary_indices;
  // sensor info
  base::SensorInfo sensor_info;
  // reserve string
  std::string reserve;

  void Reset() {
    if (cloud) {
      cloud->clear();
    }
    if (world_cloud) {
      world_cloud->clear();
    }
    timestamp = 0.0;
    lidar2world_pose = Eigen::Affine3d::Identity();
    novatel2world_pose = Eigen::Affine3d::Identity();
    if (hdmap_struct) {
      hdmap_struct->road_boundary.clear();
      hdmap_struct->road_polygons.clear();
      hdmap_struct->junction_polygons.clear();
      hdmap_struct->hole_polygons.clear();
    }
    segmented_objects.clear();
    tracked_objects.clear();
    roi_indices.indices.clear();
    non_ground_indices.indices.clear();
    secondary_indices.indices.clear();
  }

  void FilterPointCloud(base::PointCloud<base::PointF> *filtered_cloud,
                        const std::vector<uint32_t> &indices) {
    if (cloud && filtered_cloud) {
      filtered_cloud->CopyPointCloudExclude(*cloud, indices);
    }
  }
};  // struct LidarFrame
```

2.lidar_obstacle_detection.cc

/zhito/modules/perception/lidar/app/lidar_obstacles_detection.cc

**Process():**

```cpp
      LidarProcessResult LidarObstacleDetection::Process(const LidarObstacleDetectionOptions &options,const std::shared_ptr<apollo::drivers::PointCloud const> &message, LidarFrame *frame)
      {
        const auto &sensor_name = options.sensor_name;
        // 用来屏蔽无效參数的,消除警告
        PERF_FUNCTION_WITH_INDICATOR(options.sensor_name);

        PERF_BLOCK_START();

        PointCloudPreprocessorOptions preprocessor_options;        // 传感器转GPS的外参 
        preprocessor_options.sensor2novatel_extrinsics = options.sensor2novatel_extrinsics;
        PERF_BLOCK_END_WITH_INDICATOR(sensor_name, "preprocess");
        // 点云预处理
        if (cloud_preprocessor_->Preprocess(preprocessor_options, message, frame)) 
        {
          return ProcessCommon(options, frame);          // 模型推理
        }
        return LidarProcessResult(LidarErrorCode::PointCloudPreprocessorError,
                                  "Failed to preprocess point cloud.");
      }
```

**Preprocess():**去除点云中的NaN点，对xyz范围过滤，剔除车身周围点，然后将点云（位置xyz，时间戳，高度height，beam_id，标签label）形式存储到LidarFrame结构体中，后将点云转换到世界坐标系下

```cpp
bool PointCloudPreprocessor::Preprocess(
    const PointCloudPreprocessorOptions& options,
    const std::shared_ptr<apollo::drivers::PointCloud const>& message,
    LidarFrame* frame) const {
  if (frame == nullptr) {
    return false;
  }
  if (frame->cloud == nullptr) {
    // 点云对象池，结合单例设计模式
    frame->cloud = base::PointFCloudPool::Instance().Get();
  }
  if (frame->world_cloud == nullptr) {
    frame->world_cloud = base::PointDCloudPool::Instance().Get();
  }
  frame->cloud->set_timestamp(message->measurement_time());
  if (message->point_size() > 0) {
    // 设置该帧点云数大小
    frame->cloud->reserve(message->point_size());
    base::PointF point;
    for (int i = 0; i < message->point_size(); ++i) {
      const apollo::drivers::PointXYZIT& pt = message->point(i);
      // 过滤无效点
      if (filter_naninf_points_) {
        if (std::isnan(pt.x()) || std::isnan(pt.y()) || std::isnan(pt.z())) {
          continue;
        }
        // 过滤超范围的点
        if (fabs(pt.x()) > kPointInfThreshold ||
            fabs(pt.y()) > kPointInfThreshold ||
            fabs(pt.z()) > kPointInfThreshold) {
          continue;
        }
      }
      Eigen::Vector3d vec3d_lidar(pt.x(), pt.y(), pt.z());
      // 点在GPS坐标系的xyz位置
      Eigen::Vector3d vec3d_novatel = options.sensor2novatel_extrinsics * vec3d_lidar;
      // 过滤车身范围内的点云，消除车身反射的影响
      if (filter_nearby_box_points_ && vec3d_novatel[0] < box_forward_x_ &&
          vec3d_novatel[0] > box_backward_x_ &&
          vec3d_novatel[1] < box_forward_y_ &&
          vec3d_novatel[1] > box_backward_y_) {
        continue;
      }
      // Z方向点云过滤
      if (filter_high_z_points_ && pt.z() > z_threshold_) {
        continue;
      }
      point.x = pt.x();
      point.y = pt.y();
      point.z = pt.z();
      point.intensity = static_cast<float>(pt.intensity());
      // 点的点云位置xyz，时间戳，高度height（float的最大值），beam_id(点在原始点云中的索引)，标签label
      frame->cloud->push_back(point, static_cast<double>(pt.timestamp()) * 1e-9,std::numeric_limits<float>::max(), i, 0);
    }
    // 将预处理后点云针转换到世界坐标系下
    TransformCloud(frame->cloud, frame->lidar2world_pose, frame->world_cloud);
  }
  return true;
}
```

**Updata():**根据高精度地图hdmap（高度自动驾驶地图），查询当前帧点云的位置（常用采用ndt点云定位，它是一种scan-to-map的点云配准算法），获取高精地图中定位位置后，查找离定位位置距离为roi_search_distance_的所有道路、交叉路口的信息的road_polygons、road_boundary、hole_polygons、junction_polygons存到frame里

```cpp
bool MapManager::Update(const MapManagerOptions& options, LidarFrame* frame) {
  if (!frame) {// 判断点云是否为空
    AINFO << "Frame is nullptr.";
    return false;
  }
  if (!(frame->hdmap_struct)) {
    frame->hdmap_struct.reset(new base::HdmapStruct); // 重置地图
  }
  if (!hdmap_input_)
  { // 看看输入的地图是否为空初始化的时候给它赋的值
    AINFO << "Hdmap input is nullptr";
    return false;
  }
  if (update_pose_) // 是否需要更新位置
  {                 // 获取自身定位
    if (!QueryPose(&(frame->lidar2world_pose))) {
      AINFO << "Failed to query updated pose.";
    }
  }

  base::PointD point; // 设置一个point接收定位信息
  point.x = frame->lidar2world_pose.translation()(0);
  point.y = frame->lidar2world_pose.translation()(1);
  point.z = frame->lidar2world_pose.translation()(2);

  /*
  获取高精地图中，离我们所在定位位置距离为roi_search_distance_的所有道路信息
  的road_polygons、road_boundary、hole_polygons、junction_polygons存到frame里
  如果没有则hdmap_input_->GetRoiHDMapStruct（）返回false，所有的道路信息置空
  */
  if (!hdmap_input_->GetRoiHDMapStruct(point, roi_search_distance_,frame->hdmap_struct)) {
    // 路面的polygons多边形信息
    frame->hdmap_struct->road_polygons.clear();
    // 道路边界线
    frame->hdmap_struct->road_boundary.clear();
    // hole_polygonsm 没太看懂，没怎么用到这个信息
    frame->hdmap_struct->hole_polygons.clear();
    // 交叉路口多边形信息
    frame->hdmap_struct->junction_polygons.clear();
    AINFO << "Failed to get roi from hdmap.";
  }
  return true;
}
```

Detect():障碍物检测

```cpp
bool PointPillarsDetection::Detect(const LidarDetectorOptions& options,
                                   LidarFrame* frame) {
  // check input
  if (frame == nullptr) {
    AERROR << "Input null frame ptr.";
    return false;
  }
  if (frame->cloud == nullptr) {
    AERROR << "Input null frame cloud.";
    return false;
  }
  if (frame->cloud->size() == 0) {
    AERROR << "Input none points.";
    return false;
  }

  // record input cloud and lidar frame
  original_cloud_ = frame->cloud;
  original_world_cloud_ = frame->world_cloud;
  lidar_frame_ref_ = frame;

  // check output
  frame->segmented_objects.clear();
  // FLAGS_gpu_id 默认为0，使用0号显卡
  if (cudaSetDevice(FLAGS_gpu_id) != cudaSuccess) {
    AERROR << "Failed to set device to gpu " << FLAGS_gpu_id;
    return false;
  }
  // 调用Tine构造函数，成员变量_start = std::chrono::system_clock::now(); // 获取系统的时间戳，单位微秒
  Timer timer;

  int num_points;
  cur_cloud_ptr_ = std::shared_ptr<base::PointFCloud>(new base::PointFCloud(*original_cloud_));

  // down sample the point cloud through filtering beams
  // FLAGS_enable_downsample_beams 默认 false
  if (FLAGS_enable_downsample_beams) {
    base::PointFCloudPtr downsample_beams_cloud_ptr(new base::PointFCloud());
    // beam_id下采样，下采样因子FLAGS_downsample_beams_factor默认为4，减少点云数据量
    if (DownSamplePointCloudBeams(original_cloud_, downsample_beams_cloud_ptr,FLAGS_downsample_beams_factor)) {
      cur_cloud_ptr_ = downsample_beams_cloud_ptr;
    } else {
      AWARN << "Down-sample beams factor must be >= 1. Cancel down-sampling."
               " Current factor: "
            << FLAGS_downsample_beams_factor;
    }
  }

  // down sample the point cloud through filtering voxel grid
  // 体素滤波下采样，FLAGS_enable_downsample_pointcloud默认为false
  if (FLAGS_enable_downsample_pointcloud) {
    pcl::PointCloud<pcl::PointXYZI>::Ptr pcl_cloud_ptr(new pcl::PointCloud<pcl::PointXYZI>());
    pcl::PointCloud<pcl::PointXYZI>::Ptr filtered_cloud_ptr(new pcl::PointCloud<pcl::PointXYZI>());
    TransformToPCLXYZI(*cur_cloud_ptr_, pcl_cloud_ptr);
    // 下采样尺寸xyz分为默认为0.01
    DownSampleCloudByVoxelGrid(pcl_cloud_ptr, filtered_cloud_ptr, FLAGS_downsample_voxel_size_x,FLAGS_downsample_voxel_size_y, FLAGS_downsample_voxel_size_z);

    // transform pcl point cloud to apollo point cloud
    base::PointFCloudPtr downsample_voxel_cloud_ptr(new base::PointFCloud());
    TransformFromPCLXYZI(filtered_cloud_ptr, downsample_voxel_cloud_ptr);
    cur_cloud_ptr_ = downsample_voxel_cloud_ptr;
  }
  // 计算下采样时间
  downsample_time_ = timer.toc(true);

  num_points = cur_cloud_ptr_->size();
  AINFO << "num points before fusing: " << num_points;

  // fuse clouds of preceding frames with current cloud
  // fuse 的是当前的点云和的点云，作用：当点云比较稀疏时，为了提升检测效果，一般会把当前帧的点云和前几帧点云融合，弥补稀疏效果
  // 点云成员变量points_timestamp_初始化
  cur_cloud_ptr_->mutable_points_timestamp()->assign(cur_cloud_ptr_->size(),0.0);
  if (FLAGS_enable_fuse_frames && FLAGS_num_fuse_frames > 1) {
    // before fusing
    // 将融合时间间隔大于0.5的点过滤
    while (!prev_world_clouds_.empty() && frame->timestamp - prev_world_clouds_.front()->get_timestamp() > FLAGS_fuse_time_interval) {
      prev_world_clouds_.pop_front();
    }
    // transform current cloud to world coordinate and save to a new ptr
    // 将当前帧的点云转到世界坐标系下，包含xyzi信息
    base::PointDCloudPtr cur_world_cloud_ptr = std::make_shared<base::PointDCloud>();
    for (size_t i = 0; i < cur_cloud_ptr_->size(); ++i) {
      auto& pt = cur_cloud_ptr_->at(i);
      Eigen::Vector3d trans_point(pt.x, pt.y, pt.z);
      trans_point = lidar_frame_ref_->lidar2world_pose * trans_point;
      PointD world_point;
      world_point.x = trans_point(0);
      world_point.y = trans_point(1);
      world_point.z = trans_point(2);
      world_point.intensity = pt.intensity;
      cur_world_cloud_ptr->push_back(world_point);
    }
    cur_world_cloud_ptr->set_timestamp(frame->timestamp);

    // fusing clouds
    for (auto& prev_world_cloud_ptr : prev_world_clouds_) {
      num_points += prev_world_cloud_ptr->size();
    }
    // 将过滤后的之前点云加入到当前帧点云中
    FuseCloud(cur_cloud_ptr_, prev_world_clouds_);

    // after fusing
    // FLAGS_num_fuse_frames 默认为5
    while (static_cast<int>(prev_world_clouds_.size()) >= FLAGS_num_fuse_frames - 1) {
      prev_world_clouds_.pop_front();
    }
    prev_world_clouds_.emplace_back(cur_world_cloud_ptr);
  }
  AINFO << "num points after fusing: " << num_points;
  // 计算fuse时间
  fuse_time_ = timer.toc(true);

  // shuffle points and cut off
  // enable_shuffle_points 默认false
  if (FLAGS_enable_shuffle_points) {
    // FLAGS_max_num_points 默认为int的最大值 2^31-1
    num_points = std::min(num_points, FLAGS_max_num_points);
    // 对[0-num_points)之间索引，打乱
    std::vector<int> point_indices = GenerateIndices(0, num_points, true);
    // 获取打乱后的点云
    base::PointFCloudPtr shuffle_cloud_ptr(new base::PointFCloud(*cur_cloud_ptr_, point_indices));
    cur_cloud_ptr_ = shuffle_cloud_ptr;
  }
  // 计算数据shuffle时间
  shuffle_time_ = timer.toc(true);

  // point cloud to array
  float* points_array = new float[num_points * FLAGS_num_point_feature]();
  // FLAGS_normalizing_factor :255
  // 过滤范围外的点云，将点云数据转为一维数组
  CloudToArray(cur_cloud_ptr_, points_array, FLAGS_normalizing_factor);
  cloud_to_array_time_ = timer.toc(true);

  // inference
  std::vector<float> out_detections;
  std::vector<int> out_labels;
  point_pillars_ptr_->DoInference(points_array, num_points, &out_detections,&out_labels);
  inference_time_ = timer.toc(true);

  // transfer output bounding boxes to objects
  GetObjects(&frame->segmented_objects, frame->lidar2world_pose,&out_detections, &out_labels);
  collect_time_ = timer.toc(true);

  delete[] points_array;
  return true;
}
```

**GetObjects():**将推理的输出结构detections和labels转换到Object，Object包含信息有：包围框的方向direction，朝向角theta，每个类别概率type_probs，小类型概率（分的更细）sub_type，lidar_supplement结构体（包含包围框8个顶点坐标cloud，8个顶点其在世界坐标系的坐标cloud_world，检测方法的类名raw_classification_methods等

```cpp
void PointPillarsDetection::GetObjects(
    std::vector<std::shared_ptr<Object>>* objects, const Eigen::Affine3d& pose,
    std::vector<float>* detections, std::vector<int>* labels) {
  // 目标个数
  int num_objects = detections->size() / FLAGS_num_output_box_feature; // FLAGS_num_output_box_feature 为 7

  objects->clear();
  // 结合单例设计模式，调用并发对象池，创建num_objects个Object对象
  base::ObjectPool::Instance().BatchGet(num_objects, objects);

  for (int i = 0; i < num_objects; ++i) {
    auto& object = objects->at(i);
    object->id = i;

    // read params of bounding box
    float x = detections->at(i * FLAGS_num_output_box_feature + 0);
    float y = detections->at(i * FLAGS_num_output_box_feature + 1);
    float z = detections->at(i * FLAGS_num_output_box_feature + 2);
    float dx = detections->at(i * FLAGS_num_output_box_feature + 4);
    float dy = detections->at(i * FLAGS_num_output_box_feature + 3);
    float dz = detections->at(i * FLAGS_num_output_box_feature + 5);
    float yaw = detections->at(i * FLAGS_num_output_box_feature + 6);
    // 获取预测的偏航角，范围在[-pi/2,pi/2]
    yaw += M_PI / 2;
    yaw = std::atan2(sinf(yaw), cosf(yaw));
    yaw = -yaw;

    // directions
    object->theta = yaw;
    object->direction[0] = cosf(yaw);
    object->direction[1] = sinf(yaw);
    object->direction[2] = 0;
    object->lidar_supplement.is_orientation_ready = true;

    // compute vertexes of bounding box and transform to world coordinate
    object->lidar_supplement.num_points_in_roi = 8;
    object->lidar_supplement.on_use = true;
    object->lidar_supplement.is_background = false;
    float roll = 0, pitch = 0;
    // 欧拉角转旋转向量
    Eigen::Quaternionf quater =
        Eigen::AngleAxisf(roll, Eigen::Vector3f::UnitX()) *
        Eigen::AngleAxisf(pitch, Eigen::Vector3f::UnitY()) *
        Eigen::AngleAxisf(yaw, Eigen::Vector3f::UnitZ());
    Eigen::Translation3f translation(x, y, z);
    // 计算放射变换矩阵，平移向量*旋转向量
    Eigen::Affine3f affine3f = translation * quater.toRotationMatrix();
    // 包围框的8个顶点坐标，8个顶点在世界坐标系下的位置
    for (float vx : std::vector<float>{dx / 2, -dx / 2}) {
      for (float vy : std::vector<float>{dy / 2, -dy / 2}) {
        for (float vz : std::vector<float>{0, dz}) {
          Eigen::Vector3f v3f(vx, vy, vz);
          v3f = affine3f * v3f;
          PointF point;
          point.x = v3f.x();
          point.y = v3f.y();
          point.z = v3f.z();
          object->lidar_supplement.cloud.push_back(point);

          Eigen::Vector3d trans_point(point.x, point.y, point.z);
          trans_point = pose * trans_point;
          PointD world_point;
          world_point.x = trans_point(0);
          world_point.y = trans_point(1);
          world_point.z = trans_point(2);
          object->lidar_supplement.cloud_world.push_back(world_point);
        }
      }
    }

    // classification
    // 枚举 MAX_OBJECT_TYPE = 6 表示大目标
    // raw_probs二维数组，表示每个分类方法的概率
    object->lidar_supplement.raw_probs.push_back(std::vector<float>(static_cast<int>(base::ObjectType::MAX_OBJECT_TYPE), 0.f));
    // Name()返回"PointPillarsDetection" ，raw_classification_methods 存储检测方法的类名
    object->lidar_supplement.raw_classification_methods.push_back(Name());
    // 获取object的子类型，比较细的划分：CAR，PEDESTRIAN，CYCLIST，UNKNOWN
    object->sub_type = GetObjectSubType(labels->at(i));
    // 大类别，分的不是很细：VEHICLE，BICYCLE，UNKNOWN_MOVABLE
    object->type = base::kSubType2TypeMap.at(object->sub_type);
    object->lidar_supplement.raw_probs.back()[static_cast<int>(object->type)] = 1.0f;
    // 每个类别的概率存储在type_probs字段
    object->type_probs.assign(object->lidar_supplement.raw_probs.back().begin(),object->lidar_supplement.raw_probs.back().end());
  }
}
```

