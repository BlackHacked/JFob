#LiDar  #笔记

原文[[3D LiDAR based Drivable Road Region Detection for Autonomous Vehicles.pdf]]

# 待办
- [ ] 图例说明diaparity[[2023-05-24]]
- [ ] 补充文章的研究问题、实现场景[[2023-05-24]]
# Research Question
a efficient non-data-driven method to segment the point cloud into clusters of drivable road region and obstacles
将点云识别为具体路况和障碍物的高效的非数据驱动方法

相关研究聚焦于对于激光雷达扫描获取的点云数据的处理，目标在于准确与高效地识别车辆行驶环境，包括路面、路边环境及障碍物等。

# Method
将3D地面和障碍物提取转换为U-V视差域中的简单二维线检测任务

## disparity image generation
通过计算左右图像之间的视差来确定物体的深度信息，这个过程中可以产生一个名为视差图的图像


U视差图更容易识别出垂直的距离差异

>U-V视差方法是一种基于视差的三维场景表达方法。它通过计算视差图像的视差直方图来生成U-视差图和V-视差图,从而描述场景的三维结构。U-视差图和V-视差图的生成过程如下:
>1. 视差图像获取:首先需要获得视差图像,它通过匹配图像对中的像素点或从三维传感器直接计算得到。视差图像中每个像素的值代表其对应点的视差量。
>2. 视差值离散化:将视差图像的视差范围离散化为固定数量的箱子,每个箱子对应一个视差值。离散化的程度决定了后续表示的精度和范围。
>3. 直方图生成:沿图像的行方向(V-视差图)或列方向(U-视差图)累加属于每个箱子的像素值,得到视差直方图。直方图中的每个条目表示具有对应视差值的像素点的数量。
>4. 按索引排序:将得到的视差直方图按行/列索引进行排序,每个直方图对应图像的一行/一列。排序后的直方图作为图像的一行/一列,构成U-视差图/V-视差图。
>5. 特征表达:U-视差图和V-视差图作为三维场景的特征图像,分别表达场景在不同视差下的轮廓结构和高度结构。它们捕获了场景的空间关系,为后续处理提供了较为简洁的三维结构表达。
>U-V视差方法通过计算和表达视差图像的统计特征,提供一种相对简单直接的三维场景理解方式。但它存在一定的信息损失,精度也依赖于视差图像的质量。所以,该方法更适用于初步表达场景结构,为后续处理提供参考。它还需要与其他手段结合,才能获得更加全面准确的三维场景描述。

>7. 点云数据获取:获得LiDAR点云数据,包括XYZ坐标和强度信息等。点云密度和FOV视角范围根据实际LiDAR参数确定。
>8. 点云预处理:包括点云的去噪、填充空缺点和体素网格化等。这可以简化后续计算,提高点云质量。
>9. 点云配准:使点云和图像达到同一坐标系,这需要外部的IMU和GNSS信息以及人工标定点云与图像之间的变换参数。配准是点云和图像融合的基础。
>10. 点云投影:将三维点云投影到二维图像平面,获取每个点的图像坐标。这需要内参(主点坐标、焦距)和外参(旋转平移矩阵)等参数,采用中心投影模型实现点云到图像的映射。
>11. 视差计算:计算图像上对应点(从点云投影获得,或使用特征点匹配)之间的视差。视差公式采用立体视觉中的基本公式,利用点云的深度/范围信息直接计算得出。
>12. 视差图像生成:将计算得到的视差值赋予到图像坐标对应的像素上,生成视差图像。视差图像反映了场景的空间相关性,但会存在缺失区域。
>13. 视差图像插值:对视差图像进行插值填补,生成完整的视差图像。可以采用最近邻插值或体素插值等方法。插值可以增加视差图像的完备性,但也引入了误差。
>14. 视差直方图生成:根据视差图像,分别沿行和列方向累加同视差的像素,得到视差直方图。再将这些直方图按索引排列,得到U-视差图和V-视差图。
>15. 特征 expressing:U-V视差图作为特征图像,表达场景的三维结构,为后续处理提供特征。也可以将视差直方图、体素等作为特征表达。

## crude obstacle removal
对图像做预处理，识别并移除图像中的杂物和噪声（减少计算负担和误差）
将U视差图中高强度的垂直线识别为障碍物，有助于利用V视差图更准确地提取道路轮廓。

## road profile extraction
道路几何信息（道路宽度、倾斜角度）提取
利用霍夫变换/几何哈希等方法拟合V视差图汇总的连续曲线，即为道路表面
地面表面的边界使用索贝尔算子识别。索贝尔算子可用以加强道路表面在V视差图内的投影，方便筛除离群值。

>Common line extraction algorithms like Hough transform
>[[baseline algorithm]] mostly corresponds to the left ground surface
>根据3.1.4节中描述的线性特征，我们可以推断通过前面的步骤，在V-disparity图中具有高强度的像素很可能对应地面表面，并且应该形成一个连续的曲线。在一般的城市场景中，结构良好的地面表面大多由一个单一平面组成，在V-disparity图中会被投影为一条理想的直线。因此，传统的二维线拟合算法，如霍夫变换、几何哈希等，被证明适用且可靠，但对于非平坦或多平面的地面表面情况失败。

>一般来说，地面表面的投影周围是低强度的像素。我们不使用刚性模型进行拟合，而是使用[[Sobel梯度算子]]来检测相应的边缘。该算子使用两个3x3的卷积核与V-disparity图进行卷积运算，计算垂直和水平导数的近似值
>


## candidate boundary point identification
识别道路边界，通过检测边缘和颜色等特征确定道路边界的可能位置（便于路面分割和场景理解）
A simple [[thresholding]] operation is applied to filter out the road boundary candidate points. 
使用阈值处理道路边界点云
利用三种特征描述器为每个点响应一个值，判断该值是否属于阈值区间。
特征描述器：3D表面曲率；高程方差特征；线性回归的最小二乘误差特征



## road boundary regression
通过识别出的道路边界点推断整体道路边界的形状和位置。
Least Trimmed Squares Regression (LTSR) 
最小截断平方和回归，是稳健回归技术的一种，目标函数是小的[[残差和]]
是一种回归方法，它在最小二乘回归的基础上，通过去除一些数据点的影响来提高模型的鲁棒性。
在路缘识别中，LTSR可以应用于拟合道路边缘的模型。因为道路边缘通常是由一些局部特征点（如道路边缘的拐角点）组成的，而这些点可能会被异常点（如离群值）干扰。通过采用LTSR方法，可以去除这些异常点的影响，提高模型的鲁棒性。
具体来说，对于道路边缘识别任务，可以通过收集车辆行驶时的激光雷达或摄像头数据来获取道路边缘点的坐标信息。然后，将这些坐标点作为LTSR方法的输入数据，拟合出一条道路边缘线的模型。在拟合过程中，采用LTSR方法可以去除掉离群值的干扰，提高模型的精度和鲁棒性。
总的来说，LTSR方法可以在道路边缘识别等任务中起到很好的作用，帮助提高模型的鲁棒性和精度。


![[Pasted image 20230507195810.png]]




# Related work
### rigid model fitting
将整体交通场景分成几何结构（道路表面、路缘石、杆子、平面、拐角等）。建立刚体模型来描述这些结构。

#### Road surface 道路表面
一般道路表面被假设为一个理想的平面，传统的平面提取方法包括：
##### [[the random sample consensus]] (RANSAC) 
从一组数据中估计出模型参数的算法，通常用于拟合直线、平面、曲线等几何模型。
##### [[Hough based methods]]
用于在图像或点云数据中检测几何形状
##### [[normal estimation]]
法向量估计

#### Road boundary 路边
定位和识别道路边界
路缘、草坪、沟渠、护栏都在环境中呈现出不同的高程。通常使用差分滤波器对单个激光雷达扫描数据中提取道路边界信息，与不同种类的数据（高程、距离「[[range]]：每个激光束发射后，返回到激光雷达的时间和激光速度之间的乘积」、俯视图欧几里得位置）做卷积。
此外，也会利用一些前置信息，比如路面宽度和路缘高度等，提升识别准确性。
[[the least trimmed squares regression method]]

#### Lane mark路面标记
通过[[大津算法]]来区分路面标记和沥青

### Occupancy Grid Map based [[占据网格地图]]
在目标检测任务中，可以将每个网格看作一个离散的空间单元，通过对每个网格进行占据状态的标记，来表示该网格是否被目标占据。这样可以方便地对目标进行检测和跟踪，也有助于规划机器人的移动轨迹，避免碰撞和障碍。

### Disparity based 视差
通过视差推断深度等3D信息
#### [[U-V-disparity]] 
UV视差是将两个摄像头拍摄到的像素点在图像平面上的坐标转化为(u,v)坐标系中的像素点坐标，可以将像素点的水平视差和垂直视差分别表示为U和V坐标轴上的坐标值。
将3D的地面和障碍物在2D的UV坐标系中表示为一条简单的分段线性曲线。其中，地面在UV视差图中表示为一条水平的直线，而障碍物则表示为一条竖直的直线，还可以通过在UV视差图上进行曲线拟合，提取车道线、坑洼等道路特征。

#### Stixel world
从立体图像中提取出代表物体的垂直柱状结构

#### Lidar-histogram








## Ground Surface Extraction


## Road Boundary Detection


