{
	"nodes":[
		{"type":"text","text":"\n![[Pasted image 20230531082031.png]]","id":"171c247a7ff143a5","x":-240,"y":-1180,"width":440,"height":360},
		{"type":"text","text":"# 地面分割方法\n1. raw data to point cloud data\n2. preprocess #♠︎\n3. data fusion\n4. ground filtering #♣︎\n5. object detection #♥︎\n6. shape extraction #♦︎\n\n\n","id":"e6d3ff1b7d602e13","x":240,"y":-1180,"width":340,"height":360},
		{"type":"text","text":"# Camera RADAR and LiDAR\n## 传播介质\nCamera：[[可见光]]\nRADAR：[[无线电波]]\nLiDAR：[[激光]]\n\n## 环境影响因素\nCamera：环境光、视野范围、遮挡（雨雪天气等）\nRADAR\nLiDAR：雨雪雾等天气中对激光的吸收或散射\n\n## 视场\nCamera：一般为30°、50°、60°、100°、120°，检测距离一般为150 - 170 m，\n[[RADAR]]：测距250-300m、角分辨率1度以上、测量范围300米\n[[LiDAR]]：\nrotor based 水平视场角为360°，垂直视场角一般为40°、角分辨率0.1º左右、测量范围200米\n\nSolid-state(MEMS/OPA)、flash-based：视场角范围呼应应用场景的要求。对于远距离雷达，垂直FOV在20-40°，水平FOV在120°左右，最远测距距离在200m左右，在120m-150m达到最佳效果。对于近距离雷达，垂直FOV在70°-120°范围内为益，水平FOV在140°左右。最远测距距离在50m左右，在10m-30m达到最佳效果","id":"24b8cf9e67758041","x":-240,"y":-780,"width":440,"height":820},
		{"type":"text","text":"# Ground modelling\n\n## plane fitting\n### [[A_multi-modal_system_for_road_detection_and_segmentation.pdf]]\n![[Pasted image 20230531153453.png]]\n#### road boudary detection #♥︎\n![[Pasted image 20230531163545.png]]\n\n#### road plane detection #♥︎\n假设路缘立在路面上，在将路缘点识别出来的基础上，关注路缘点的垂直方向Z轴的坐标，在前进方向X轴划分cell，取每个cell内最低点加入list，在list的基础上使用[[the random sample consensus|RANSAC]]拟合地面。\n\n#### road plane extraction #♦︎\n>the orthogonaldistance between any 3D point and the plane is computed.\nBased on this criterion, ground points are extracted through a thresholding procedure.\n\n### [[Fast_Object_Segmentation_Pipeline_for_Point_Clouds_Using_Robot_Operating_System.pdf]]\n\n## Line extraction 线性拟合\n[[Fast_segmentation_of_3D_point_clouds_for_ground_vehicles.pdf]]\n水平方向360度做角度微分，针对每个切片内的点按半径的长短分区拟合线段，通过为线段的斜率和截距设置阈值判断地面点。\n![[Pasted image 20230602151010.png]]\n## Gaussian process regression based [[高斯过程回归]]\n","id":"f7db44427be28503","x":840,"y":-1600,"width":720,"height":2120},
		{"type":"text","text":"# 2.5D elevation map based \n以将地面分割为grid cell为基础的方法\n## 2.5D elevation map\n[[Representing a 3-D Environment with a 2%-D Map Structure.pdf]]\n\n### Preprocess #♠︎\n>具体来说,2.5D地图用二维数组实现,每个数组元素代表地图上的一个区域(Cell),并记录该Cell内最高的障碍物高度z’和机器人检测到该障碍物的概率p’。\n\n2.5D地图引入一个二维数组标记XY平面上的cell，进而记录每个cell内的高度等参数。\n每个cell内所有点的平均高度、[[基于2.5D map计算网格内点的表面梯度]]、方差等\n\n![[Pasted image 20230531135329.png]]\n[[Hybrid_elevation_maps_3D_surface_models_for_segmentation.pdf]]\n\n### ground filtering #♣︎\n1. clustering\n\n### object detection #♥︎\n1. [[multiresolution ground surface distraction]]\n[[Obstacle Avoidance and Safeguarding for a Lunar Rover.pdf]]\n\n\n\n### 问题\noverhanging\n![[Pasted image 20230531141306.png]]\n\n\n\n## Occupancy grid map #♠︎\n[[High_resolution_maps_from_wide_angle_sonar.pdf]]\n利用声纳获取环境测距测量结果，将结果投影到地图，标记empty、occupied和unknown。\n二维图：\n![[Pasted image 20230531143958.png]]\n\n[[A_Probability_Occupancy_Grid_Based_Approach_for_Real-Time_LiDAR_Ground_Segmentation.pdf]]\n输出cell属于地面的可能性\n![[Pasted image 20230601150005.png]]\n\n\n\n","id":"910c38ab0b4abf16","x":840,"y":-4040,"width":720,"height":2400},
		{"type":"text","text":"# adjacent points and local features 邻近点和局部特征\n## channel-based\n[[Ground Segmentation Methods for AutomotiveLiDAR Sensors.canvas|Ground Segmentation Methods for AutomotiveLiDAR Sensors]]\n\n\n","id":"1563c6d6e07a0f80","x":840,"y":560,"width":720,"height":400},
		{"id":"75175c37e1f99b7b","x":840,"y":1060,"width":720,"height":1000,"type":"text","text":"# Learn based "}
	],
	"edges":[
		{"id":"f13bd3d8ed5178d7","fromNode":"e6d3ff1b7d602e13","fromSide":"right","toNode":"910c38ab0b4abf16","toSide":"left"},
		{"id":"f470dca0d5b705f7","fromNode":"e6d3ff1b7d602e13","fromSide":"right","toNode":"f7db44427be28503","toSide":"left"},
		{"id":"4654d37fe7b76da3","fromNode":"e6d3ff1b7d602e13","fromSide":"right","toNode":"1563c6d6e07a0f80","toSide":"left"}
	]
}